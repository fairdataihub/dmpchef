[![Contributors](https://img.shields.io/github/contributors/fairdataihub/LLM-RAG-demo?style=flat-square&logo=github&logoColor=white&color=2ea44f)](https://github.com/fairdataihub/LLM-RAG-demo/graphs/contributors)
[![Stars](https://img.shields.io/github/stars/fairdataihub/LLM-RAG-demo?style=flat-square&logo=github&logoColor=white&color=f9d949)](https://github.com/fairdataihub/LLM-RAG-demo/stargazers)
[![Issues](https://img.shields.io/github/issues/fairdataihub/LLM-RAG-demo?style=flat-square&logo=github&logoColor=white&color=ff7a00)](https://github.com/fairdataihub/LLM-RAG-demo/issues)
[![License](https://img.shields.io/github/license/fairdataihub/LLM-RAG-demo?style=flat-square&color=1f6feb)](LICENSE)
[![DOI](https://img.shields.io/badge/DOI-pending-9e9e9e?style=flat-square)](#how-to-cite)

# DMP Chef
DMP Chef is an open-source (MIT License), Python-based pipeline that draft funder-compliant **Data Management & Sharing Plan (DMPs)** using a **Large Language Model (LLM), such as Llama 3.3** 

It supports two modes entirely in Python:
- **RAG**: Retrieves related guidance from an indexed document collection and uses it to ground the draft. In this mode, the pipeline can **ingest documents**, **build and search an index**, and **draft a DMP**.
- **No-RAG**: Generates the draft only from the userâ€™s project inputs (no retrieval).

This project is part of a broader extension of the DMP Tool platform. The ultimate goal is to integrate the DMP Chef pipeline into the [DMP Tool](https://dmptool.org/) platform, providing researchers with a familiar and convenient user interface that does not require any coding knowledge.

ðŸ‘‰ Learn more: **[DMP-Chef](https://fairdataihub.org/dmp-chef)**.

---
## Standards followed
The overall codebase is organized in alignment with the **[FAIR-BioRS guidelines](https://fair-biors.org/)**. All Python code follows **[PEP 8](https://peps.python.org/pep-0008/)** conventions, including consistent formatting, inline comments, and docstrings. Project dependencies are fully captured in **[requirements.txt](https://github.com/fairdataihub/dmpchef/blob/main/requirements.txt)**. We also retain **[dmp-template](https://github.com/fairdataihub/dmpchef/blob/main/data/inputs/dmp-template.md)** as inside the prompt template used by the DMP generation workflow.


## Main files

- **[`dmpchef/api.py`](https://github.com/fairdataihub/dmpchef/blob/main/dmpchef/api.py)** â€” Public, importable API:
- **[`src/core_pipeline.py`](https://github.com/fairdataihub/dmpchef/blob/main/src/core_pipeline.py)** â€” Core generation logic (No-RAG vs RAG ; retrieval â†’ prompt â†’ generate).
- **[`src/NIH_data_ingestion.py`](https://github.com/fairdataihub/dmpchef/blob/main/src/NIH_data_ingestion.py)** â€” NIH/DMPTool ingestion to collect reference PDFs for RAG
- **[`main.py`](https://github.com/fairdataihub/dmpchef/blob/main/main.py)** â€” Command-line entry point for running the pipeline end-to-end.
- **[`demo.ipynb`](https://github.com/fairdataihub/dmpchef/blob/main/demo.ipynb)** â€” Jupyter demo showing.


---

## Repository Structure
```text
dmpchef/
â”‚â”€â”€ main.py                 # CLI entry point (run pipeline end-to-end)
â”‚â”€â”€ README.md               # Project overview + usage
â”‚â”€â”€ requirements.txt        # Python dependencies
â”‚â”€â”€ setup.py                # Packaging (editable installs via pip install -e .)
â”‚â”€â”€ pyproject.toml          # Build system config (wheel builds)
â”‚â”€â”€ MANIFEST.in             # Include non-code files in distributions
â”‚â”€â”€ demo.ipynb              # Notebook demo: import + run generate()
â”‚â”€â”€ LICENSE
â”‚â”€â”€ .gitignore
â”‚â”€â”€ .env                    # Local env vars (do not commit)
â”‚
â”œâ”€â”€ dmpchef/                # Installable Python package (public API)
â”‚   â”œâ”€â”€ __init__.py         # Exports: generate, draft, prepare_nih_corpus
â”‚   â””â”€â”€ api.py              # Importable API used by notebooks/backends
â”‚
â”œâ”€â”€ config/                 # Configuration
â”‚   â”œâ”€â”€ config.yaml         # Main settings (models, paths, retriever params)
â”‚   â””â”€â”€ config_schema.py    # Validation/schema helpers (optional)
â”‚
â”œâ”€â”€ data/                   # Local workspace data + artifacts (not guaranteed in wheel)
â”‚   â”œâ”€â”€ inputs/             # Templates + examples
â”‚   â”‚   â”œâ”€â”€ nih-dms-plan-template.docx  # NIH blank Word template
â”‚   â”‚   â””â”€â”€ input.json                  # Example request file
â”‚   â”œâ”€â”€ web_links.json      # Seed links for NIH/DMPTool ingestion (used by src/NIH_data_ingestion.py)
â”‚   â”œâ”€â”€ database/             # Reference PDFs collected for NIH RAG (optional)
â”‚   â”œâ”€â”€ index/              # Vector index artifacts (e.g., FAISS)
â”‚   â”œâ”€â”€ outputs/            # Generated artifacts
â”‚   â”‚   â”œâ”€â”€ markdown/       # Generated Markdown DMPs
â”‚   â”‚   â”œâ”€â”€ docx/           # Generated DOCX DMPs (template-preserving)
â”‚   â”‚   â”œâ”€â”€ json/           # DMPTool-compatible JSON outputs
â”‚   â”‚   â”œâ”€â”€ pdf/            # Optional PDFs converted from DOCX
â”‚   â”‚   â””â”€â”€ debug/          # Optional retrieval debug outputs (retrieved context, logs, etc.)
â”‚   â””â”€â”€ data_ingestion/     # Session folders + manifests from crawling
â”‚
â”œâ”€â”€ src/                    # Core implementation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core_pipeline.py    # Pipeline logic (RAG/no-RAG)
â”‚   â””â”€â”€ NIH_data_ingestion.py # NIH/DMPTool crawl â†’ export PDFs to data/NIH_95
â”‚
â”œâ”€â”€ prompt/                 # Prompt templates/utilities
â”‚   â””â”€â”€ prompt_library.py
â”‚
â”œâ”€â”€ utils/                  # Shared helpers
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”œâ”€â”€ dmptool_json.py
â”‚   â””â”€â”€ nih_docx_writer.py
â”‚
â”œâ”€â”€ logger/                 # Logging utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ custom_logger.py
â”‚
â”œâ”€â”€ exception/              # Custom exceptions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ custom_exception.py
â”‚
â”œâ”€â”€ notebook_DMP_RAG/       # Notebooks/experiments (non-production)
â””â”€â”€ venv/                   # Local virtualenv (ignore in git)



```
## Setup (Local Development)

### Step 1 â€” Clone the repository
```bash
git clone https://github.com/fairdataihub/dmpchef.git
cd dmpchef
code .
```

### Step 2 â€” Create and activate a virtual environment

**Windows (cmd):**
```bash
python -m venv venv
venv\Scripts\activate.bat
```

**macOS/Linux:**
```bash
python -m venv venv
source venv/bin/activate
```

### Step 3 â€” Install dependencies
```bash
pip install -r requirements.txt
# or (recommended for local dev)
pip install -e .
```

---

## Run DMP Chef

### Option A â€” Jupyter demo
Use **[`demo.ipynb`](https://github.com/fairdataihub/dmpchef/blob/main/demo_import.ipynb)**.

### Option B â€” CLI: Command-line entry point for running the pipeline end-to-end

Use  **[`main.py`](https://github.com/fairdataihub/dmpchef/blob/main/main.py)** 

---

## Inputs
- **Input.JSON**: A single JSON file (e.g., `data/inputs/input.json`) that tells the pipeline what to generate.
 **Top-level fields**

```json
{
  "config": { ... },
  "inputs": { ... }
}
```
### `config` (Execution Settings)

- **config.funding.agency**: Funder key (e.g., `NIH`; future-ready for others like `NSF`).
- **config.funding.subagency**: Optional sub-agency (e.g., `NIMH`).
- **config.pipeline.rag**: `true` / `false` (optional). If omitted, the pipeline uses the YAML default (`rag.enabled`).
- **config.pipeline.llm**: LLM settings (e.g., `provider`, `model_name`).
- **config.export**: Output toggles (`md`, `docx`, `pdf`, `dmptool_json`).

### `inputs` 
- **inputs**: A dictionary of user/project fields used to draft the plan include:
  - `research_context`, `data_types`, `data_source`, `human_subjects`, `consent_status`, `data_volume`, etc.

## Outputs (Project Fields)

- **Markdown**: the generated funder-aligned DMP narrative (currently NIH structure).
- **DOCX**: generated using the funder template (NIH template today) to preserve official formatting.
- **PDF**: created by converting the DOCX (platform-dependent; typically works on Windows/macOS with Word).
- **JSON**: a **DMPTool-compatible** JSON file (`*.dmptool.json`).


---

## License
This work is licensed under the **[MIT License](https://opensource.org/license/mit/)**. See **[LICENSE](https://github.com/fairdataihub/dmpchef/blob/main/LICENSE)** for more information.


---

## Feedback and contribution
Use **[GitHub Issues](https://github.com/fairdataihub/dmpchef/issues)** to submit feedback, report problems, or suggest improvements.  
You can also **fork** the repository and submit a **Pull Request** with your changes.

---

## How to cite
If you use this code, please cite this repository using the **versioned DOI on Zenodo** for the specific release you used (instructions will be added once the Zenodo record is available). For now, you can reference the repository here: **[fairdataihub/dmpchef](https://github.com/fairdataihub/dmpchef)**.

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1339d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1 ready (reuses pipeline index, notebook-local outputs)\n",
      "CONFIG_YAML : c:\\Users\\Nahid\\dmpchef\\config\\config.yaml\n",
      "PROJECT_ROOT: c:\\Users\\Nahid\\dmpchef\n",
      "ROOT_DIR    : C:\\Users\\Nahid\\dmpchef\n",
      "NOTEBOOK_DIR: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\n",
      "NB_OUT_ROOT : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\n",
      "RUN_DIR     : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\n",
      "INDEX_DIR (pipeline): C:\\Users\\Nahid\\dmpchef\\data\\vector_db\\NIH_all_db\n",
      "OUTPUT_MD (notebook): c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\md\\generated_dmp.md\n",
      "OUTPUT_DOCX(notebook): c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\docx\\generated_dmp.docx\n",
      "DATA_PDFS   : C:\\Users\\Nahid\\dmpchef\\data\\data_ingestion\\NIH_all\n",
      "EXCEL_PATH  : C:\\Users\\Nahid\\dmpchef\\data\\inputs\\inputs.xlsx\n",
      "TEMPLATE_MD : C:\\Users\\Nahid\\dmpchef\\data\\inputs\\dmp-template.md\n",
      "EMBED_MODEL : sentence-transformers/all-MiniLM-L6-v2\n",
      "LLM_MODEL   : llama3.3:latest\n",
      "TOP_K       : 6\n",
      "EMBED_DEVICE: cuda | BATCH: 256 | NORMALIZE: True\n",
      "HF_CACHE_DIR: C:\\Users\\Nahid\\dmpchef\\data\\cache\\hf | local_files_only=True | allow_download_if_missing=True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1 — Imports, Config (YAML), and Helpers\n",
    "# (Notebook-safe outputs under: ./noteboo_DMP_RAG/)\n",
    "# Reuses pipeline FAISS index (read-only)\n",
    "# ============================================\n",
    "import os, re, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pypandoc  # for Markdown → DOCX\n",
    "\n",
    "# --- LangChain Core ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- Resolve project root (works in notebook or script) ----------\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parents[1]  # when running a .py script\n",
    "except NameError:\n",
    "    PROJECT_ROOT = Path.cwd().parent                    # when running inside Jupyter\n",
    "\n",
    "# ---------- Notebook-only output root (keeps experiments separate) ----------\n",
    "NOTEBOOK_DIR = Path.cwd()  # folder where the notebook is running\n",
    "NB_OUT_ROOT = NOTEBOOK_DIR / \"Output_experiemnt_RAG3_NIH_all\"\n",
    "\n",
    "# Optional: timestamped run folder so outputs never overwrite\n",
    "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = NB_OUT_ROOT / f\"run_{RUN_ID}\"\n",
    "\n",
    "NB_MD_DIR   = RUN_DIR / \"md\"\n",
    "NB_DOCX_DIR = RUN_DIR / \"docx\"\n",
    "\n",
    "for p in [NB_OUT_ROOT, RUN_DIR, NB_MD_DIR, NB_DOCX_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- YAML loader + path resolver ----------\n",
    "def load_yaml_config(cfg_path: Path) -> dict:\n",
    "    cfg_path = Path(cfg_path)\n",
    "    if not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"Config YAML not found: {cfg_path}\")\n",
    "    with cfg_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    if not isinstance(cfg, dict):\n",
    "        raise ValueError(f\"Config YAML must parse to a dict. Got: {type(cfg)}\")\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def resolve_from_root(project_root: Path, root_dir_value: str | Path) -> Path:\n",
    "    \"\"\"\n",
    "    YAML root_dir:\n",
    "      - \".\" means project root\n",
    "      - relative paths are relative to project root\n",
    "      - absolute paths are used as-is\n",
    "    \"\"\"\n",
    "    p = Path(root_dir_value).expanduser()\n",
    "    if p.is_absolute():\n",
    "        return p.resolve()\n",
    "    return (project_root / p).resolve()\n",
    "\n",
    "\n",
    "def resolve_path(base: Path, rel_or_abs: str | Path | None) -> Path | None:\n",
    "    \"\"\"Resolve a path relative to `base` if not absolute. Keep None as None.\"\"\"\n",
    "    if rel_or_abs is None:\n",
    "        return None\n",
    "    p = Path(rel_or_abs).expanduser()\n",
    "    if p.is_absolute():\n",
    "        return p.resolve()\n",
    "    return (base / p).resolve()\n",
    "\n",
    "\n",
    "# ---------- Choose your YAML file here ----------\n",
    "CONFIG_YAML = PROJECT_ROOT / \"config\" / \"config.yaml\"\n",
    "cfg = load_yaml_config(CONFIG_YAML)\n",
    "\n",
    "# ---------- Root dir from YAML ----------\n",
    "ROOT_DIR = resolve_from_root(PROJECT_ROOT, cfg[\"root_dir\"])\n",
    "\n",
    "# ---------- Paths from YAML (READ-ONLY / pipeline assets) ----------\n",
    "DATA_PDFS  = resolve_path(ROOT_DIR, cfg[\"paths\"][\"data_pdfs\"])        # optional here, but kept for reference\n",
    "INDEX_DIR  = resolve_path(ROOT_DIR, cfg[\"paths\"][\"index_dir\"])        # <-- reuse pipeline index (read-only)\n",
    "EXCEL_PATH = resolve_path(ROOT_DIR, cfg[\"paths\"][\"excel_path\"])       # optional depending on your notebook\n",
    "\n",
    "# Template (read-only)\n",
    "TEMPLATE_MD = resolve_path(\n",
    "    ROOT_DIR,\n",
    "    cfg[\"paths\"].get(\"template_md\", \"data/inputs/dmp-template.md\")\n",
    ")\n",
    "\n",
    "# ---------- RAG params ----------\n",
    "TOP_K = int(cfg[\"rag\"][\"retriever_top_k\"])\n",
    "\n",
    "# ---------- Models ----------\n",
    "EMBED_MODEL = cfg[\"models\"][\"embedding_model\"]\n",
    "LLM_MODEL   = cfg[\"models\"][\"llm_name\"]\n",
    "\n",
    "EMBED_DEVICE       = cfg[\"models\"][\"embedding_device\"]\n",
    "EMBED_BATCH_SIZE   = int(cfg[\"models\"][\"embedding_batch_size\"])\n",
    "NORMALIZE_EMBEDS   = bool(cfg[\"models\"][\"normalize_embeddings\"])\n",
    "HF_CACHE_DIR       = resolve_path(ROOT_DIR, cfg[\"models\"][\"hf_cache_dir\"])\n",
    "LOCAL_FILES_ONLY   = bool(cfg[\"models\"][\"local_files_only\"])\n",
    "ALLOW_DL_IF_MISS   = bool(cfg[\"models\"][\"allow_download_if_missing\"])\n",
    "\n",
    "# ---------- Notebook-only outputs (always under noteboo_DMP_RAG/) ----------\n",
    "OUTPUT_MD   = NB_MD_DIR / \"generated_dmp.md\"\n",
    "OUTPUT_DOCX = NB_DOCX_DIR / \"generated_dmp.docx\"\n",
    "\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def create_folder(folderpath: Path | str) -> None:\n",
    "    Path(folderpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath: Path | str, filename: str, text: str) -> Path:\n",
    "    create_folder(folderpath)\n",
    "    out_path = Path(folderpath) / filename\n",
    "    out_path.write_text(text, encoding=\"utf-8\")\n",
    "    print(\"Saved:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "def md_to_docs(md_filepath: Path | str, docx_folderpath: Path | str, docx_filename: str) -> Path:\n",
    "    create_folder(docx_folderpath)\n",
    "    out_path = Path(docx_folderpath) / docx_filename\n",
    "    pypandoc.convert_file(str(md_filepath), \"docx\", outputfile=str(out_path))\n",
    "    print(\"Converted:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "def clean_filename(name: str) -> str:\n",
    "    \"\"\"Remove illegal characters from filenames (Windows-safe).\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name)).strip()\n",
    "\n",
    "\n",
    "# ---------- Sanity print ----------\n",
    "print(\"STEP 1 ready (reuses pipeline index, notebook-local outputs)\")\n",
    "print(f\"CONFIG_YAML : {CONFIG_YAML}\")\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"ROOT_DIR    : {ROOT_DIR}\")\n",
    "print(f\"NOTEBOOK_DIR: {NOTEBOOK_DIR}\")\n",
    "print(f\"NB_OUT_ROOT : {NB_OUT_ROOT}\")\n",
    "print(f\"RUN_DIR     : {RUN_DIR}\")\n",
    "\n",
    "print(f\"INDEX_DIR (pipeline): {INDEX_DIR}\")\n",
    "print(f\"OUTPUT_MD (notebook): {OUTPUT_MD}\")\n",
    "print(f\"OUTPUT_DOCX(notebook): {OUTPUT_DOCX}\")\n",
    "\n",
    "print(f\"DATA_PDFS   : {DATA_PDFS}\")\n",
    "print(f\"EXCEL_PATH  : {EXCEL_PATH}\")\n",
    "print(f\"TEMPLATE_MD : {TEMPLATE_MD}\")\n",
    "\n",
    "print(f\"EMBED_MODEL : {EMBED_MODEL}\")\n",
    "print(f\"LLM_MODEL   : {LLM_MODEL}\")\n",
    "print(f\"TOP_K       : {TOP_K}\")\n",
    "print(f\"EMBED_DEVICE: {EMBED_DEVICE} | BATCH: {EMBED_BATCH_SIZE} | NORMALIZE: {NORMALIZE_EMBEDS}\")\n",
    "print(f\"HF_CACHE_DIR: {HF_CACHE_DIR} | local_files_only={LOCAL_FILES_ONLY} | allow_download_if_missing={ALLOW_DL_IF_MISS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc0461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1391.84it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index (read-only) from: C:\\Users\\Nahid\\dmpchef\\data\\vector_db\\NIH_all_db\n",
      "Retriever ready | top_k=6 | embed_model=sentence-transformers/all-MiniLM-L6-v2 | device=cuda | backend=langchain_huggingface\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 2 — Load pipeline FAISS index (READ-ONLY) and create retriever\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Prefer new HuggingFace integration if installed; fallback to langchain_community\n",
    "try:\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings  # type: ignore\n",
    "    _EMB_BACKEND = \"langchain_huggingface\"\n",
    "except Exception:\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings  # type: ignore\n",
    "    _EMB_BACKEND = \"langchain_community\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Ensure HF uses the same cache directory you configured (very important in notebooks)\n",
    "# This helps avoid \"couldn't find them in the cached files\" surprises.\n",
    "if HF_CACHE_DIR is not None:\n",
    "    os.environ.setdefault(\"HF_HOME\", str(HF_CACHE_DIR))\n",
    "\n",
    "def _pick_device(requested: str) -> str:\n",
    "    req = (requested or \"auto\").lower().strip()\n",
    "    if req in (\"auto\", \"cuda\"):\n",
    "        return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return \"cpu\"\n",
    "\n",
    "device = _pick_device(EMBED_DEVICE)\n",
    "\n",
    "def _make_embeddings(local_only: bool):\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=EMBED_MODEL,\n",
    "        cache_folder=str(HF_CACHE_DIR) if HF_CACHE_DIR is not None else None,\n",
    "        model_kwargs={\n",
    "            \"device\": device,\n",
    "            \"local_files_only\": bool(local_only),\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            \"batch_size\": int(EMBED_BATCH_SIZE),\n",
    "            \"normalize_embeddings\": bool(NORMALIZE_EMBEDS),\n",
    "        },\n",
    "    )\n",
    "\n",
    "# 1) Try per YAML: local_files_only\n",
    "try:\n",
    "    embeddings = _make_embeddings(local_only=LOCAL_FILES_ONLY)\n",
    "except Exception as e1:\n",
    "    # 2) If offline cache miss but allowed to download, retry online\n",
    "    if LOCAL_FILES_ONLY and ALLOW_DL_IF_MISS:\n",
    "        print(\"Embeddings not found in cache; retrying with download enabled...\")\n",
    "        embeddings = _make_embeddings(local_only=False)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "index_dir = Path(INDEX_DIR)\n",
    "faiss_path = index_dir / \"index.faiss\"\n",
    "pkl_path   = index_dir / \"index.pkl\"\n",
    "\n",
    "if not (faiss_path.exists() and pkl_path.exists()):\n",
    "    raise FileNotFoundError(\n",
    "        \"FAISS index files not found.\\n\"\n",
    "        f\"Expected:\\n- {faiss_path}\\n- {pkl_path}\\n\"\n",
    "        \"Run your pipeline build_index.py or fix config.paths.index_dir.\"\n",
    "    )\n",
    "\n",
    "print(\"Loading FAISS index (read-only) from:\", index_dir)\n",
    "vectorstore = FAISS.load_local(\n",
    "    str(index_dir),\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": int(TOP_K)})\n",
    "\n",
    "print(\n",
    "    \"Retriever ready\",\n",
    "    f\"top_k={TOP_K}\",\n",
    "    f\"embed_model={EMBED_MODEL}\",\n",
    "    f\"device={device}\",\n",
    "    f\"backend={_EMB_BACKEND}\",\n",
    "    sep=\" | \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ecf6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel loaded successfully: 26 rows\n",
      "DMP Markdown template loaded.\n",
      "RAG chain initialized with model: llama3.3:latest\n",
      "RAG chain ready for generation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 3 — Load Excel + Template, Build Few-shot, and Build RAG Chain\n",
    "# ============================================\n",
    "import re\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# ---- Guard: Step 2 must run first ----\n",
    "if \"retriever\" not in globals():\n",
    "    raise RuntimeError(\"`retriever` is not defined. Run STEP 2 (load FAISS index) before STEP 3.\")\n",
    "\n",
    "# --- Load Excel file ---\n",
    "if EXCEL_PATH is None or not EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Excel file not found: {EXCEL_PATH}\")\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.fillna(\"\")\n",
    "print(f\"Excel loaded successfully: {len(df)} rows\")\n",
    "\n",
    "# --- Load Markdown Template ---\n",
    "if TEMPLATE_MD is None or not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"Template file not found: {TEMPLATE_MD}\")\n",
    "\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(\"DMP Markdown template loaded.\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Build RAG chain (RAG grounding)\n",
    "# ============================================\n",
    "def build_rag_chain(retriever, llm_model=LLM_MODEL, n_few_shot: int = 3):\n",
    "    llm = Ollama(model=llm_model)\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    def format_docs(docs):\n",
    "        if not docs:\n",
    "            return \"\"\n",
    "        formatted = []\n",
    "        for d in docs:\n",
    "            page = d.metadata.get(\"page\", d.metadata.get(\"page_number\", \"\"))\n",
    "            source = d.metadata.get(\"source\", d.metadata.get(\"file_path\", \"\"))\n",
    "            page_disp = (page + 1) if isinstance(page, int) else page\n",
    "            formatted.append(f\"[Page {page_disp}] {source}\\n{(d.page_content or '').strip()}\")\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "\n",
    "    prompt_template = \"\"\"You are an expert biomedical data steward and grant writer.\n",
    "Create a high-quality NIH Data Management and Sharing Plan (DMSP) based on the retrieved NIH context and the user's query.\n",
    "\n",
    "---- Context from NIH Repository (grounding) ----\n",
    "{context}\n",
    "\n",
    "---- Question ----\n",
    "{question}\n",
    "\n",
    "Rules:\n",
    "- Use NIH context when relevant; do NOT invent policy details.\n",
    "- If a specific policy detail is not supported by the provided context, write: \"Not specified in provided NIH context.\"\n",
    "- Follow the NIH template structure and keep section titles unchanged when the template is provided.\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | parser\n",
    "    )\n",
    "\n",
    "    print(f\"RAG chain initialized with model: {llm_model}\")\n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "rag_chain = build_rag_chain(retriever, n_few_shot=3)\n",
    "print(\"RAG chain ready for generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308a44de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook output folders:\n",
      "RUN_DIR    : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\n",
      "MD folder  : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\md\n",
      "DOCX folder: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\docx\n",
      "LOG CSV    : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\rag_generated_dmp_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating DMP for: Clinical and MRI data from human research participants\n",
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\md\\Clinical and MRI data from human research participants.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:   4%|▍         | 1/26 [12:53<5:22:23, 773.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\docx\\Clinical and MRI data from human research participants.docx\n",
      "\n",
      "Generating DMP for: Genomic data from human research participants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:   8%|▊         | 2/26 [25:14<5:01:41, 754.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\md\\Genomic data from human research participants.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\docx\\Genomic data from human research participants.docx\n",
      "\n",
      "Generating DMP for: Genomic data from a non-human source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  12%|█▏        | 3/26 [34:41<4:16:27, 669.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\md\\Genomic data from a non-human source.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\docx\\Genomic data from a non-human source.docx\n",
      "\n",
      "Generating DMP for: Secondary data analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  15%|█▌        | 4/26 [45:56<4:06:03, 671.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\md\\Secondary data analysis.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\docx\\Secondary data analysis.docx\n",
      "\n",
      "Generating DMP for: Human clinical and genomics data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  19%|█▉        | 5/26 [1:00:05<4:17:25, 735.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\md\\Human clinical and genomics data.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260225_140527\\docx\\Human clinical and genomics data.docx\n",
      "\n",
      "Generating DMP for: Gene expression analysis data from non-human model organism (zebrafish)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  19%|█▉        | 5/26 [1:06:39<4:39:56, 799.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 94\u001b[0m\n\u001b[0;32m     81\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124mCreate a complete NIH Data Management and Sharing Plan (DMSP) for the project titled: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m     83\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mdmp_template_text\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m         safe_title \u001b[38;5;241m=\u001b[39m sanitize_filename(title)\n\u001b[0;32m     97\u001b[0m         md_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msafe_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3157\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3155\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3156\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3157\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3158\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:380\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    378\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    381\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    382\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    383\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    384\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    385\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    386\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    387\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    388\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    389\u001b[0m         )\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    392\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:791\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    790\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:1013\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    995\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    996\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    997\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         )\n\u001b[0;32m   1012\u001b[0m     ]\n\u001b[1;32m-> 1013\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m   1014\u001b[0m         prompts,\n\u001b[0;32m   1015\u001b[0m         stop,\n\u001b[0;32m   1016\u001b[0m         run_managers,\n\u001b[0;32m   1017\u001b[0m         new_arg_supported\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1019\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1021\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1022\u001b[0m         callback_managers[idx]\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[0;32m   1031\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:817\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    808\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    814\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    816\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 817\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    818\u001b[0m                 prompts,\n\u001b[0;32m    819\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    820\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    821\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    822\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    823\u001b[0m             )\n\u001b[0;32m    824\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    825\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    826\u001b[0m         )\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    828\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:437\u001b[0m, in \u001b[0;36mOllama._generate\u001b[1;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m--> 437\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_stream_with_aggregation(\n\u001b[0;32m    438\u001b[0m         prompt,\n\u001b[0;32m    439\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    440\u001b[0m         images\u001b[38;5;241m=\u001b[39mimages,\n\u001b[0;32m    441\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    442\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:349\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    342\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    347\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[0;32m    348\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m    351\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py:194\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[1;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    188\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    192\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    193\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[0;32m    196\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    197\u001b[0m         api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    199\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[0;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[0;32m    871\u001b[0m ):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\requests\\utils.py:562\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    561\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    563\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\urllib3\\response.py:1250\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1250\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp)\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39mhas_unconsumed_tail)\n\u001b[0;32m   1256\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\urllib3\\response.py:1418\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1420\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nahid\\dmpchef\\venv\\lib\\site-packages\\urllib3\\response.py:1333\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1333\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 4 — RAG-Based DMP Generation (Notebook-safe, no icons)\n",
    "# Writes ONLY under: Output_7/run_*/ (from STEP 1)\n",
    "# Reuses: df, dmp_template_text, rag_chain (from STEP 3)\n",
    "# ============================================\n",
    "import re\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- Ensure notebook output folders exist ----------\n",
    "for p in [NB_OUT_ROOT, RUN_DIR, NB_MD_DIR, NB_DOCX_DIR]:\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Output log (inside the same run folder) ----------\n",
    "OUTPUT_LOG = RUN_DIR / \"rag_generated_dmp_log.csv\"\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def sanitize_filename(name: str, max_len: int = 140) -> str:\n",
    "    \"\"\"\n",
    "    Windows-safe filename:\n",
    "    - remove illegal characters\n",
    "    - collapse whitespace\n",
    "    - limit length to avoid long-path issues\n",
    "    \"\"\"\n",
    "    s = re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name).strip())\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    if len(s) > max_len:\n",
    "        s = s[:max_len].rstrip()\n",
    "    return s or \"untitled\"\n",
    "\n",
    "def save_md(folderpath: Path, filename: str, text: str) -> Path:\n",
    "    folderpath.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = folderpath / filename\n",
    "    out_path.write_text(text, encoding=\"utf-8\")\n",
    "    print(\"Saved:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "def md_to_docx(md_filepath: Path, docx_folder: Path, docx_filename: str) -> Path:\n",
    "    docx_folder.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = docx_folder / docx_filename\n",
    "    pypandoc.convert_file(str(md_filepath), \"docx\", outputfile=str(out_path))\n",
    "    print(\"Converted:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "# ---------- Guards ----------\n",
    "if \"rag_chain\" not in globals():\n",
    "    raise RuntimeError(\"rag_chain not found. Run STEP 2 (retriever) + STEP 3 (rag_chain) first.\")\n",
    "if \"df\" not in globals():\n",
    "    raise RuntimeError(\"df not found. Run STEP 3 (Excel load) first.\")\n",
    "if \"dmp_template_text\" not in globals():\n",
    "    raise RuntimeError(\"dmp_template_text not found. Run STEP 3 (template load) first.\")\n",
    "\n",
    "print(\"Notebook output folders:\")\n",
    "print(\"RUN_DIR    :\", RUN_DIR)\n",
    "print(\"MD folder  :\", NB_MD_DIR)\n",
    "print(\"DOCX folder:\", NB_DOCX_DIR)\n",
    "print(\"LOG CSV    :\", OUTPUT_LOG)\n",
    "\n",
    "# ---------- Main generation ----------\n",
    "records = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating NIH DMPs\"):\n",
    "    title = str(row.get(\"title\", \"\")).strip()\n",
    "    if not title:\n",
    "        continue\n",
    "\n",
    "    print(\"\\nGenerating DMP for:\", title)\n",
    "\n",
    "    # Build proposal details from the row (only element* columns)\n",
    "    element_cols = [c for c in df.columns if str(c).startswith(\"element\")]\n",
    "    element_texts = []\n",
    "    for col in element_cols:\n",
    "        val = str(row.get(col, \"\")).strip()\n",
    "        if val:\n",
    "            element_texts.append(f\"{col.upper()}: {val}\")\n",
    "    query_data = \"\\n\".join(element_texts).strip()\n",
    "\n",
    "    # Build question for rag_chain (retrieval + few-shot happens inside chain)\n",
    "    question = f\"\"\"\n",
    "Create a complete NIH Data Management and Sharing Plan (DMSP) for the project titled: \"{title}\".\n",
    "\n",
    "Use the NIH DMSP Markdown template below and DO NOT change section titles.\n",
    "\n",
    "Project background / proposal details:\n",
    "{query_data}\n",
    "\n",
    "NIH DMSP Markdown template:\n",
    "{dmp_template_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.invoke(question)\n",
    "\n",
    "        safe_title = sanitize_filename(title)\n",
    "        md_filename = f\"{safe_title}.md\"\n",
    "        docx_filename = f\"{safe_title}.docx\"\n",
    "\n",
    "        md_path = save_md(NB_MD_DIR, md_filename, response)\n",
    "        docx_path = md_to_docx(md_path, NB_DOCX_DIR, docx_filename)\n",
    "\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"MD_Path\": str(md_path),\n",
    "            \"DOCX_Path\": str(docx_path),\n",
    "            \"Question_Preview\": question[:1000],\n",
    "            \"Generated_DMP_Preview\": response[:1000],\n",
    "            \"Error\": \"\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error generating DMP for:\", title, \"|\", str(e))\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"MD_Path\": \"\",\n",
    "            \"DOCX_Path\": \"\",\n",
    "            \"Question_Preview\": question[:1000],\n",
    "            \"Generated_DMP_Preview\": \"\",\n",
    "            \"Error\": str(e)\n",
    "        })\n",
    "\n",
    "# ---------- Save log ----------\n",
    "pd.DataFrame(records).to_csv(OUTPUT_LOG, index=False, encoding=\"utf-8\")\n",
    "print(\"\\nFinished processing all rows.\")\n",
    "print(\"CSV log saved to:\", OUTPUT_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold PDF folder     : C:\\Users\\Nahid\\dmpchef\\data\\inputs\\gold_dmps | exists= True\n",
      "Generated MD folder : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\md | exists= True\n",
      "Evaluation output   : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\evaluation_results\n",
      "Found generated .md files: 26\n",
      "Found gold .pdf files    : 26\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1634.20it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready.\n",
      "Indexed generated DMPs: 26\n",
      "Indexed gold PDFs     : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching & Comparing DMPs: 100%|██████████| 26/26 [00:05<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\evaluation_results\\full_dmp_pdf_comparison_fuzzy.csv\n",
      "Total matched DMP pairs: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 5 — Full DMP Comparison: Markdown (Generated) vs PDF (Gold, Fuzzy Matching)\n",
    "# Notebook-safe , and writes results ONLY under your current RUN_DIR\n",
    "# Uses:\n",
    "#   - NB_MD_DIR (generated .md from STEP 4)\n",
    "#   - RUN_DIR   (evaluation output folder)\n",
    "# You set GOLD_DIR manually (PDF gold folder)\n",
    "# ============================================\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths (Notebook-safe)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Generated markdown comes from the current run folder (STEP 4)\n",
    "GENERATED_DIR = Path(NB_MD_DIR)\n",
    "\n",
    "# 2) Gold PDFs: set your correct folder here\n",
    "#    Examples you can try (uncomment the one that matches your repo):\n",
    "# GOLD_DIR = ROOT_DIR / \"data\" / \"inputs\" / \"gold_dmps\"\n",
    "# GOLD_DIR = ROOT_DIR / \"data\" / \"gold_dmps\"\n",
    "GOLD_DIR = ROOT_DIR / \"data\" / \"inputs\" / \"gold_dmps\"\n",
    "\n",
    "# 3) Evaluation output: store under this run\n",
    "EVAL_DIR = Path(RUN_DIR) / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Gold PDF folder     :\", GOLD_DIR,   \"| exists=\", GOLD_DIR.exists())\n",
    "print(\"Generated MD folder :\", GENERATED_DIR, \"| exists=\", GENERATED_DIR.exists())\n",
    "print(\"Evaluation output   :\", EVAL_DIR)\n",
    "\n",
    "gold_pdf_count = len(list(GOLD_DIR.glob(\"*.pdf\"))) if GOLD_DIR.exists() else 0\n",
    "gen_md_count   = len(list(GENERATED_DIR.glob(\"*.md\"))) if GENERATED_DIR.exists() else 0\n",
    "print(\"Found generated .md files:\", gen_md_count)\n",
    "print(\"Found gold .pdf files    :\", gold_pdf_count)\n",
    "\n",
    "if gen_md_count == 0:\n",
    "    raise FileNotFoundError(f\"No generated Markdown files found in: {GENERATED_DIR}\")\n",
    "if gold_pdf_count == 0:\n",
    "    raise FileNotFoundError(f\"No gold PDF files found in: {GOLD_DIR}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Models\n",
    "# ------------------------------------------------------------\n",
    "print(\"Loading models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"Models ready.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------------------\n",
    "def normalize_name(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # remove special tags some LLMs produce\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "    # remove markdown formatting\n",
    "    text = re.sub(r\"#+\\s*\", \"\", text)\n",
    "    text = re.sub(r\"\\*\\*|\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    txt = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                txt += page.get_text(\"text\") + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(\"Error reading PDF:\", pdf_path.name, \"|\", str(e))\n",
    "    return clean_text(txt)\n",
    "\n",
    "def chunk_text(text: str, size: int = 300) -> list[str]:\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "def compare_chunked(gold_text: str, gen_text: str, model) -> tuple[float, float]:\n",
    "    gold_chunks = chunk_text(gold_text)\n",
    "    gen_chunks  = chunk_text(gen_text)\n",
    "\n",
    "    sbert_scores = []\n",
    "    rouge_scores = []\n",
    "\n",
    "    # Pre-embed generated chunks once (much faster)\n",
    "    gen_embs = model.encode(gen_chunks, convert_to_tensor=True) if gen_chunks else None\n",
    "\n",
    "    for g in gold_chunks:\n",
    "        emb_g = model.encode(g, convert_to_tensor=True)\n",
    "\n",
    "        # SBERT max similarity over generated chunks\n",
    "        if gen_embs is not None and len(gen_chunks) > 0:\n",
    "            sims = util.cos_sim(emb_g, gen_embs)[0].cpu().numpy()\n",
    "            sbert_scores.append(float(np.max(sims)))\n",
    "        else:\n",
    "            sbert_scores.append(0.0)\n",
    "\n",
    "        # ROUGE-L max recall over generated chunks\n",
    "        if gen_chunks:\n",
    "            rouge_chunk_scores = [rouge.score(g, gg)[\"rougeL\"].recall for gg in gen_chunks]\n",
    "            rouge_scores.append(float(np.max(rouge_chunk_scores)))\n",
    "        else:\n",
    "            rouge_scores.append(0.0)\n",
    "\n",
    "    return float(np.mean(sbert_scores)), float(np.mean(rouge_scores))\n",
    "\n",
    "def best_fuzzy_match(target: str, gold_names: list[str], threshold: float = 0.6) -> tuple[str | None, float]:\n",
    "    best_match, best_score = None, 0.0\n",
    "    for g in gold_names:\n",
    "        score = SequenceMatcher(None, target, g).ratio()\n",
    "        if score > best_score:\n",
    "            best_match, best_score = g, score\n",
    "    return (best_match, best_score) if best_score >= threshold else (None, best_score)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Collect files\n",
    "# ------------------------------------------------------------\n",
    "gold_files = {normalize_name(f.stem): f for f in GOLD_DIR.glob(\"*.pdf\")}\n",
    "gen_files  = {normalize_name(f.stem): f for f in GENERATED_DIR.glob(\"*.md\")}\n",
    "print(\"Indexed generated DMPs:\", len(gen_files))\n",
    "print(\"Indexed gold PDFs     :\", len(gold_files))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compare\n",
    "# ------------------------------------------------------------\n",
    "results = []\n",
    "gold_keys = list(gold_files.keys())\n",
    "\n",
    "for name, gen_path in tqdm(gen_files.items(), desc=\"Matching & Comparing DMPs\"):\n",
    "    best_match, match_score = best_fuzzy_match(name, gold_keys, threshold=0.6)\n",
    "    if not best_match:\n",
    "        continue\n",
    "\n",
    "    gold_path = gold_files[best_match]\n",
    "\n",
    "    gold_text = extract_text_from_pdf(gold_path)\n",
    "    gen_text  = clean_text(gen_path.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
    "\n",
    "    if not gold_text or not gen_text:\n",
    "        continue\n",
    "\n",
    "    sbert_sim, rouge_l = compare_chunked(gold_text, gen_text, sbert)\n",
    "\n",
    "    results.append({\n",
    "        \"Generated_File\": gen_path.name,\n",
    "        \"Matched_Gold_PDF\": gold_path.name,\n",
    "        \"Match_Score\": round(match_score, 3),\n",
    "        \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "        \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "out_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "df_results.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nResults saved to:\", out_path)\n",
    "print(\"Total matched DMP pairs:\", len(df_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b15824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold Excel: C:\\Users\\Nahid\\dmpchef\\data\\inputs\\inputs.xlsx | exists= True\n",
      "Generated MD folder: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\md | exists= True\n",
      "Eval output folder: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\evaluation_results\n",
      "Found generated Markdown files: 26\n",
      "Loaded gold projects: 26\n",
      "Gold element columns used: ['element_1a', 'element_1b', 'element_1c', 'element_2', 'element_3', 'element_4a', 'element_4b', 'element_4c', 'element_5a', 'element_5b', 'element_5c', 'element_6']\n",
      "Loading evaluation models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1855.37it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing element-level: 100%|██████████| 26/26 [00:01<00:00, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Element-level similarity saved to: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\evaluation_results\\element_similarity_exact_titles.csv\n",
      "Total element–section best matches: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 6 — Element-Level Comparison with Gold Standard \n",
    "# Compares: generated Markdown sections (NB_MD_DIR) vs gold Excel element fields\n",
    "# Writes:   RUN_DIR/evaluation_results/element_similarity_exact_titles.csv\n",
    "# ============================================\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths (Notebook-safe; reuse STEP 1 variables)\n",
    "# ------------------------------------------------------------\n",
    "# Generated markdown from current run\n",
    "GENERATED_DIR = Path(NB_MD_DIR)\n",
    "\n",
    "# Gold Excel: your reference file (same Excel you used to generate)\n",
    "GOLD_PATH = Path(EXCEL_PATH)  # from STEP 1\n",
    "\n",
    "# Evaluation output goes inside this run folder\n",
    "EVAL_DIR = Path(RUN_DIR) / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Gold Excel:\", GOLD_PATH, \"| exists=\", GOLD_PATH.exists())\n",
    "print(\"Generated MD folder:\", GENERATED_DIR, \"| exists=\", GENERATED_DIR.exists())\n",
    "print(\"Eval output folder:\", EVAL_DIR)\n",
    "\n",
    "if not GOLD_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Gold Excel not found: {GOLD_PATH}\")\n",
    "if not GENERATED_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Generated Markdown folder not found: {GENERATED_DIR}\")\n",
    "\n",
    "md_files = sorted(GENERATED_DIR.glob(\"*.md\"))\n",
    "print(\"Found generated Markdown files:\", len(md_files))\n",
    "if not md_files:\n",
    "    raise FileNotFoundError(f\"No .md files found in: {GENERATED_DIR}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load gold reference (Excel)\n",
    "# ------------------------------------------------------------\n",
    "df_gold = pd.read_excel(GOLD_PATH)\n",
    "df_gold.columns = df_gold.columns.str.strip().str.lower()\n",
    "df_gold = df_gold.fillna(\"\").astype(str)\n",
    "\n",
    "def normalize_title(name: str) -> str:\n",
    "    name = str(name).lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "if \"title\" not in df_gold.columns:\n",
    "    raise KeyError(\"Gold Excel must contain a 'title' column.\")\n",
    "\n",
    "df_gold[\"title_norm\"] = df_gold[\"title\"].apply(normalize_title)\n",
    "\n",
    "gold_elements = [\n",
    "    \"element_1a\",\"element_1b\",\"element_1c\",\n",
    "    \"element_2\",\"element_3\",\n",
    "    \"element_4a\",\"element_4b\",\"element_4c\",\n",
    "    \"element_5a\",\"element_5b\",\"element_5c\",\n",
    "    \"element_6\"\n",
    "]\n",
    "gold_elements = [c for c in gold_elements if c in df_gold.columns]\n",
    "\n",
    "print(\"Loaded gold projects:\", len(df_gold))\n",
    "print(\"Gold element columns used:\", gold_elements)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Models\n",
    "# ------------------------------------------------------------\n",
    "print(\"Loading evaluation models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"Models ready.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Markdown parsing helpers\n",
    "# ------------------------------------------------------------\n",
    "def is_title(line: str) -> bool:\n",
    "    s = line.strip()\n",
    "    # Markdown headers OR numbered bold titles like: 1. **Data Types**\n",
    "    return s.startswith(\"#\") or bool(re.match(r\"^\\s*\\d*\\.?\\s*\\*\\*.*\\*\\*\\s*$\", s))\n",
    "\n",
    "def strip_llm_noise(text: str) -> str:\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "    return text\n",
    "\n",
    "def extract_sections(md_path: Path) -> pd.DataFrame:\n",
    "    text = md_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    text = strip_llm_noise(text)\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    entries, current_title, buf = [], None, []\n",
    "\n",
    "    for ln in lines:\n",
    "        if is_title(ln):\n",
    "            if current_title and any(x.strip() for x in buf):\n",
    "                entries.append({\n",
    "                    \"Section Title\": current_title.strip(),\n",
    "                    \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "                })\n",
    "            current_title, buf = ln, []\n",
    "        else:\n",
    "            buf.append(ln)\n",
    "\n",
    "    if current_title and any(x.strip() for x in buf):\n",
    "        entries.append({\n",
    "            \"Section Title\": current_title.strip(),\n",
    "            \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compare (exact normalized title match)\n",
    "# ------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "# Pre-index gold rows by normalized title for fast lookup\n",
    "gold_by_title = {r[\"title_norm\"]: r for _, r in df_gold.iterrows()}\n",
    "\n",
    "for md_file in tqdm(md_files, desc=\"Comparing element-level\"):\n",
    "    gen_title_raw = md_file.stem\n",
    "    gen_title_norm = normalize_title(gen_title_raw)\n",
    "\n",
    "    gold_row = gold_by_title.get(gen_title_norm)\n",
    "    if gold_row is None:\n",
    "        continue\n",
    "\n",
    "    gold_title = gold_row[\"title\"]\n",
    "\n",
    "    # Collect non-empty gold element texts\n",
    "    gold_texts = {e: str(gold_row.get(e, \"\")).strip() for e in gold_elements}\n",
    "    gold_texts = {k: v for k, v in gold_texts.items() if v}\n",
    "\n",
    "    if not gold_texts:\n",
    "        continue\n",
    "\n",
    "    # Extract generated sections\n",
    "    gen_df = extract_sections(md_file)\n",
    "    if gen_df.empty:\n",
    "        continue\n",
    "\n",
    "    # Clean sections and drop empties\n",
    "    gen_df[\"Generated Content\"] = gen_df[\"Generated Content\"].astype(str).str.strip()\n",
    "    gen_df = gen_df[gen_df[\"Generated Content\"].str.len() > 0]\n",
    "    if gen_df.empty:\n",
    "        continue\n",
    "\n",
    "    # Embed all generated sections once (speedup)\n",
    "    section_texts = gen_df[\"Generated Content\"].tolist()\n",
    "    section_embs = sbert.encode(section_texts, convert_to_tensor=True)\n",
    "\n",
    "    for element, gold_text in gold_texts.items():\n",
    "        emb_gold = sbert.encode(gold_text, convert_to_tensor=True)\n",
    "\n",
    "        sims = util.cos_sim(emb_gold, section_embs)[0].cpu().numpy()\n",
    "        best_idx = int(np.argmax(sims))\n",
    "        best_sbert = float(sims[best_idx])\n",
    "\n",
    "        best_section_title = gen_df.iloc[best_idx][\"Section Title\"]\n",
    "        best_section_text  = gen_df.iloc[best_idx][\"Generated Content\"]\n",
    "        best_rouge = float(rouge.score(gold_text, best_section_text)[\"rougeL\"].recall)\n",
    "\n",
    "        results.append({\n",
    "            \"Gold Project\": gold_title,\n",
    "            \"Gold Element\": element,\n",
    "            \"Generated File\": md_file.name,\n",
    "            \"Best Generated Section Title\": best_section_title,\n",
    "            \"SBERT_Similarity\": round(best_sbert, 4),\n",
    "            \"ROUGE_L_Recall\": round(best_rouge, 4),\n",
    "        })\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Save\n",
    "# ------------------------------------------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "df_results.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nElement-level similarity saved to:\", out_path)\n",
    "print(\"Total element–section best matches:\", len(df_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d77ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_DIR: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\evaluation_results\n",
      "Loaded full-document rows: 26\n",
      "Loaded element-level rows: 312\n",
      "\n",
      "Full-document summary (mean by Generated_File):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_File</th>\n",
       "      <th>SBERT_mean</th>\n",
       "      <th>ROUGE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysis of social media posts.md</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.4339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic Research from a Non-Human Source Example.md</td>\n",
       "      <td>0.7808</td>\n",
       "      <td>0.4705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Data from Human Research Participants.md</td>\n",
       "      <td>0.6758</td>\n",
       "      <td>0.2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical and MRI data from human research part...</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.2653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical data (human biospecimens).md</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical data from human research participants...</td>\n",
       "      <td>0.7615</td>\n",
       "      <td>0.4439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drug discovery including intellectual property.md</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>0.4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gene expression analysis data from non-human m...</td>\n",
       "      <td>0.8140</td>\n",
       "      <td>0.5315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genomic data from a non-human source.md</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>0.2764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Genomic data from human research participants.md</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HeLa Cell Whole Genome Sequence (DNA or RNA).md</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.5478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Human Clinical Trial Data.md</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human clinical and genomic data-NIA.md</td>\n",
       "      <td>0.8060</td>\n",
       "      <td>0.5956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human clinical and genomics data.md</td>\n",
       "      <td>0.6639</td>\n",
       "      <td>0.4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human genomic data.md</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human survey data.md</td>\n",
       "      <td>0.6937</td>\n",
       "      <td>0.3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Non-human data (primates).md</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.3381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Non-human data (rodents)-NIA.md</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Secondary Data Analysis Example.md</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>0.4140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Secondary Data Analysis on Data from Human Sub...</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>0.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Secondary data analysis-NIA.md</td>\n",
       "      <td>0.7479</td>\n",
       "      <td>0.3121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Secondary data analysis.md</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.2516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Survey and Interview Example.md</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>0.3114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Survey and interview data-NIA.md</td>\n",
       "      <td>0.7811</td>\n",
       "      <td>0.4177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Survey, interview, and biological data (tiered...</td>\n",
       "      <td>0.8021</td>\n",
       "      <td>0.4614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Technology development.md</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Generated_File  SBERT_mean  ROUGE_mean\n",
       "0                   Analysis of social media posts.md      0.8082      0.4339\n",
       "1   Basic Research from a Non-Human Source Example.md      0.7808      0.4705\n",
       "2   Clinical Data from Human Research Participants.md      0.6758      0.2520\n",
       "3   Clinical and MRI data from human research part...      0.7154      0.2653\n",
       "4               Clinical data (human biospecimens).md      0.7622      0.4827\n",
       "5   Clinical data from human research participants...      0.7615      0.4439\n",
       "6   Drug discovery including intellectual property.md      0.7997      0.4646\n",
       "7   Gene expression analysis data from non-human m...      0.8140      0.5315\n",
       "8             Genomic data from a non-human source.md      0.7162      0.2764\n",
       "9    Genomic data from human research participants.md      0.7241      0.2671\n",
       "10    HeLa Cell Whole Genome Sequence (DNA or RNA).md      0.8847      0.5478\n",
       "11                       Human Clinical Trial Data.md      0.6443      0.2818\n",
       "12             Human clinical and genomic data-NIA.md      0.8060      0.5956\n",
       "13                Human clinical and genomics data.md      0.6639      0.4576\n",
       "14                              Human genomic data.md      0.6690      0.3873\n",
       "15                               Human survey data.md      0.6937      0.3215\n",
       "16                       Non-human data (primates).md      0.7166      0.3381\n",
       "17                    Non-human data (rodents)-NIA.md      0.7951      0.6742\n",
       "18                 Secondary Data Analysis Example.md      0.8018      0.4140\n",
       "19  Secondary Data Analysis on Data from Human Sub...      0.7953      0.4540\n",
       "20                     Secondary data analysis-NIA.md      0.7479      0.3121\n",
       "21                         Secondary data analysis.md      0.6156      0.2516\n",
       "22                    Survey and Interview Example.md      0.7086      0.3114\n",
       "23                   Survey and interview data-NIA.md      0.7811      0.4177\n",
       "24  Survey, interview, and biological data (tiered...      0.8021      0.4614\n",
       "25                          Technology development.md      0.6731      0.6833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall full-document means:\n",
      "{'SBERT_overall_mean': 0.7444884615384617, 'ROUGE_overall_mean': 0.41528076923076923}\n",
      "\n",
      "Element-level summary (mean ± sd):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>SBERT_mean_sd</th>\n",
       "      <th>ROUGE_mean_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>element_1a</td>\n",
       "      <td>0.84 ± 0.16</td>\n",
       "      <td>0.56 ± 0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>element_1b</td>\n",
       "      <td>0.77 ± 0.15</td>\n",
       "      <td>0.50 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>element_1c</td>\n",
       "      <td>0.84 ± 0.12</td>\n",
       "      <td>0.63 ± 0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>element_2</td>\n",
       "      <td>0.85 ± 0.11</td>\n",
       "      <td>0.58 ± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>element_3</td>\n",
       "      <td>0.83 ± 0.11</td>\n",
       "      <td>0.54 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>element_4a</td>\n",
       "      <td>0.82 ± 0.10</td>\n",
       "      <td>0.58 ± 0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>element_4b</td>\n",
       "      <td>0.86 ± 0.13</td>\n",
       "      <td>0.63 ± 0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>element_4c</td>\n",
       "      <td>0.88 ± 0.10</td>\n",
       "      <td>0.62 ± 0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>element_5a</td>\n",
       "      <td>0.84 ± 0.15</td>\n",
       "      <td>0.61 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>element_5b</td>\n",
       "      <td>0.82 ± 0.14</td>\n",
       "      <td>0.57 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>element_5c</td>\n",
       "      <td>0.81 ± 0.16</td>\n",
       "      <td>0.54 ± 0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>element_6</td>\n",
       "      <td>0.91 ± 0.09</td>\n",
       "      <td>0.70 ± 0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Element SBERT_mean_sd ROUGE_mean_sd\n",
       "0   element_1a   0.84 ± 0.16   0.56 ± 0.37\n",
       "1   element_1b   0.77 ± 0.15   0.50 ± 0.32\n",
       "2   element_1c   0.84 ± 0.12   0.63 ± 0.34\n",
       "3    element_2   0.85 ± 0.11   0.58 ± 0.31\n",
       "4    element_3   0.83 ± 0.11   0.54 ± 0.32\n",
       "5   element_4a   0.82 ± 0.10   0.58 ± 0.29\n",
       "6   element_4b   0.86 ± 0.13   0.63 ± 0.30\n",
       "7   element_4c   0.88 ± 0.10   0.62 ± 0.28\n",
       "8   element_5a   0.84 ± 0.15   0.61 ± 0.32\n",
       "9   element_5b   0.82 ± 0.14   0.57 ± 0.32\n",
       "10  element_5c   0.81 ± 0.16   0.54 ± 0.37\n",
       "11   element_6   0.91 ± 0.09   0.70 ± 0.29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved formatted tables:\n",
      "c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\evaluation_results\\summary_full_table_mean_only.csv\n",
      "c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7_NIH_all\\run_20260220_095540\\evaluation_results\\summary_element_table_mean_sd.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 7 — Summarize Evaluation Results \n",
    "# Reads results from:\n",
    "#   RUN_DIR/evaluation_results/full_dmp_pdf_comparison_fuzzy.csv\n",
    "#   RUN_DIR/evaluation_results/element_similarity_exact_titles.csv\n",
    "# Writes summaries to the same folder.\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Notebook-safe eval directory (from STEP 1)\n",
    "# ------------------------------------------------------------\n",
    "EVAL_DIR = Path(RUN_DIR) / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"EVAL_DIR:\", EVAL_DIR)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load CSVs (fail loudly if missing)\n",
    "# ------------------------------------------------------------\n",
    "full_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "elem_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "\n",
    "if not full_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {full_path} (Run STEP 5 first)\")\n",
    "if not elem_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {elem_path} (Run STEP 6 first)\")\n",
    "\n",
    "df_full = pd.read_csv(full_path)\n",
    "df_elem = pd.read_csv(elem_path)\n",
    "\n",
    "print(\"Loaded full-document rows:\", len(df_full))\n",
    "print(\"Loaded element-level rows:\", len(df_elem))\n",
    "\n",
    "if df_full.empty:\n",
    "    raise ValueError(\"full_dmp_pdf_comparison_fuzzy.csv is empty (STEP 5 matched 0 pairs).\")\n",
    "if df_elem.empty:\n",
    "    raise ValueError(\"element_similarity_exact_titles.csv is empty (STEP 6 matched 0 pairs).\")\n",
    "\n",
    "# ============================================================\n",
    "# 1) FULL-DOCUMENT LEVEL SUMMARY (Mean by Generated_File)\n",
    "# ============================================================\n",
    "project_col = \"Generated_File\" if \"Generated_File\" in df_full.columns else df_full.columns[0]\n",
    "\n",
    "sbert_col = next((c for c in df_full.columns if \"sbert\" in c.lower()), None)\n",
    "rouge_col = next((c for c in df_full.columns if \"rouge\" in c.lower()), None)\n",
    "\n",
    "if not sbert_col or not rouge_col:\n",
    "    raise ValueError(f\"Could not find SBERT/ROUGE columns in: {df_full.columns.tolist()}\")\n",
    "\n",
    "df_full_summary = (\n",
    "    df_full.groupby(project_col)[[sbert_col, rouge_col]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# numeric + formatted columns\n",
    "df_full_summary[\"SBERT_mean\"] = df_full_summary[sbert_col].round(4)\n",
    "df_full_summary[\"ROUGE_mean\"] = df_full_summary[rouge_col].round(4)\n",
    "\n",
    "df_full_table = df_full_summary[[project_col, \"SBERT_mean\", \"ROUGE_mean\"]].rename(\n",
    "    columns={project_col: \"Generated_File\"}\n",
    ")\n",
    "\n",
    "print(\"\\nFull-document summary (mean by Generated_File):\")\n",
    "display(df_full_table)\n",
    "\n",
    "# Optional overall mean (across projects)\n",
    "overall_full = {\n",
    "    \"SBERT_overall_mean\": float(df_full_summary[\"SBERT_mean\"].mean()),\n",
    "    \"ROUGE_overall_mean\": float(df_full_summary[\"ROUGE_mean\"].mean()),\n",
    "}\n",
    "print(\"\\nOverall full-document means:\")\n",
    "print(overall_full)\n",
    "\n",
    "# ============================================================\n",
    "# 2) ELEMENT-LEVEL SUMMARY (Mean ± SD)\n",
    "# ============================================================\n",
    "elem_col = next((c for c in df_elem.columns if \"element\" in c.lower()), None)\n",
    "if not elem_col:\n",
    "    raise ValueError(f\"Could not find element column in: {df_elem.columns.tolist()}\")\n",
    "\n",
    "sbert_col_e = next((c for c in df_elem.columns if \"sbert\" in c.lower()), None)\n",
    "rouge_col_e = next((c for c in df_elem.columns if \"rouge\" in c.lower()), None)\n",
    "\n",
    "if not sbert_col_e or not rouge_col_e:\n",
    "    raise ValueError(f\"Could not find SBERT/ROUGE columns in: {df_elem.columns.tolist()}\")\n",
    "\n",
    "df_elem_summary = (\n",
    "    df_elem.groupby(elem_col)[[sbert_col_e, rouge_col_e]]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten columns\n",
    "df_elem_summary.columns = [\n",
    "    elem_col,\n",
    "    \"SBERT_mean\", \"SBERT_sd\",\n",
    "    \"ROUGE_mean\", \"ROUGE_sd\"\n",
    "]\n",
    "\n",
    "# Round for readability\n",
    "for c in [\"SBERT_mean\", \"SBERT_sd\", \"ROUGE_mean\", \"ROUGE_sd\"]:\n",
    "    df_elem_summary[c] = df_elem_summary[c].astype(float).round(4)\n",
    "\n",
    "# Add formatted strings (mean ± sd)\n",
    "df_elem_summary[\"SBERT_mean_sd\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['SBERT_mean']:.2f} ± {r['SBERT_sd']:.2f}\", axis=1\n",
    ")\n",
    "df_elem_summary[\"ROUGE_mean_sd\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['ROUGE_mean']:.2f} ± {r['ROUGE_sd']:.2f}\", axis=1\n",
    ")\n",
    "\n",
    "df_elem_table = df_elem_summary[[elem_col, \"SBERT_mean_sd\", \"ROUGE_mean_sd\"]].rename(\n",
    "    columns={elem_col: \"Element\"}\n",
    ")\n",
    "\n",
    "print(\"\\nElement-level summary (mean ± sd):\")\n",
    "display(df_elem_table)\n",
    "\n",
    "# ============================================================\n",
    "# Save tables\n",
    "# ============================================================\n",
    "out_full = EVAL_DIR / \"summary_full_table_mean_only.csv\"\n",
    "out_elem = EVAL_DIR / \"summary_element_table_mean_sd.csv\"\n",
    "\n",
    "df_full_table.to_csv(out_full, index=False, encoding=\"utf-8\")\n",
    "df_elem_table.to_csv(out_elem, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nSaved formatted tables:\")\n",
    "print(out_full)\n",
    "print(out_elem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

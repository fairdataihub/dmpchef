{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1339d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1 ready (reuses pipeline index, notebook-local outputs)\n",
      "CONFIG_YAML : c:\\Users\\Nahid\\dmpchef\\config\\config.yaml\n",
      "PROJECT_ROOT: c:\\Users\\Nahid\\dmpchef\n",
      "ROOT_DIR    : C:\\Users\\Nahid\\dmpchef\n",
      "NOTEBOOK_DIR: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\n",
      "NB_OUT_ROOT : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\n",
      "RUN_DIR     : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\n",
      "INDEX_DIR (pipeline): C:\\Users\\Nahid\\dmpchef\\data\\vector_db\\NIH_sharing_db\n",
      "OUTPUT_MD (notebook): c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\generated_dmp.md\n",
      "OUTPUT_DOCX(notebook): c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\generated_dmp.docx\n",
      "DATA_PDFS   : C:\\Users\\Nahid\\dmpchef\\data\\data_ingestion\\NIH_sharing\n",
      "EXCEL_PATH  : C:\\Users\\Nahid\\dmpchef\\data\\inputs\\inputs.xlsx\n",
      "TEMPLATE_MD : C:\\Users\\Nahid\\dmpchef\\data\\inputs\\dmp-template.md\n",
      "EMBED_MODEL : sentence-transformers/all-MiniLM-L6-v2\n",
      "LLM_MODEL   : llama3.3:latest\n",
      "TOP_K       : 6\n",
      "EMBED_DEVICE: cuda | BATCH: 256 | NORMALIZE: True\n",
      "HF_CACHE_DIR: C:\\Users\\Nahid\\dmpchef\\data\\cache\\hf | local_files_only=True | allow_download_if_missing=True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1 — Imports, Config (YAML), and Helpers\n",
    "# (Notebook-safe outputs under: ./noteboo_DMP_RAG/)\n",
    "# Reuses pipeline FAISS index (read-only)\n",
    "# ============================================\n",
    "import os, re, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pypandoc  # for Markdown → DOCX\n",
    "\n",
    "# --- LangChain Core ---\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- Resolve project root (works in notebook or script) ----------\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parents[1]  # when running a .py script\n",
    "except NameError:\n",
    "    PROJECT_ROOT = Path.cwd().parent                    # when running inside Jupyter\n",
    "\n",
    "# ---------- Notebook-only output root (keeps experiments separate) ----------\n",
    "NOTEBOOK_DIR = Path.cwd()  # folder where the notebook is running\n",
    "NB_OUT_ROOT = NOTEBOOK_DIR / \"Output_experiemnt_RAG_v1_Dmptools\"\n",
    "\n",
    "# Optional: timestamped run folder so outputs never overwrite\n",
    "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR = NB_OUT_ROOT / f\"run_{RUN_ID}\"\n",
    "\n",
    "NB_MD_DIR   = RUN_DIR / \"md\"\n",
    "NB_DOCX_DIR = RUN_DIR / \"docx\"\n",
    "\n",
    "for p in [NB_OUT_ROOT, RUN_DIR, NB_MD_DIR, NB_DOCX_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- YAML loader + path resolver ----------\n",
    "def load_yaml_config(cfg_path: Path) -> dict:\n",
    "    cfg_path = Path(cfg_path)\n",
    "    if not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"Config YAML not found: {cfg_path}\")\n",
    "    with cfg_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    if not isinstance(cfg, dict):\n",
    "        raise ValueError(f\"Config YAML must parse to a dict. Got: {type(cfg)}\")\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def resolve_from_root(project_root: Path, root_dir_value: str | Path) -> Path:\n",
    "    \"\"\"\n",
    "    YAML root_dir:\n",
    "      - \".\" means project root\n",
    "      - relative paths are relative to project root\n",
    "      - absolute paths are used as-is\n",
    "    \"\"\"\n",
    "    p = Path(root_dir_value).expanduser()\n",
    "    if p.is_absolute():\n",
    "        return p.resolve()\n",
    "    return (project_root / p).resolve()\n",
    "\n",
    "\n",
    "def resolve_path(base: Path, rel_or_abs: str | Path | None) -> Path | None:\n",
    "    \"\"\"Resolve a path relative to `base` if not absolute. Keep None as None.\"\"\"\n",
    "    if rel_or_abs is None:\n",
    "        return None\n",
    "    p = Path(rel_or_abs).expanduser()\n",
    "    if p.is_absolute():\n",
    "        return p.resolve()\n",
    "    return (base / p).resolve()\n",
    "\n",
    "\n",
    "# ---------- Choose your YAML file here ----------\n",
    "CONFIG_YAML = PROJECT_ROOT / \"config\" / \"config.yaml\"\n",
    "cfg = load_yaml_config(CONFIG_YAML)\n",
    "\n",
    "# ---------- Root dir from YAML ----------\n",
    "ROOT_DIR = resolve_from_root(PROJECT_ROOT, cfg[\"root_dir\"])\n",
    "\n",
    "# ---------- Paths from YAML (READ-ONLY / pipeline assets) ----------\n",
    "DATA_PDFS  = resolve_path(ROOT_DIR, cfg[\"paths\"][\"data_pdfs\"])        # optional here, but kept for reference\n",
    "INDEX_DIR  = resolve_path(ROOT_DIR, cfg[\"paths\"][\"index_dir\"])        # <-- reuse pipeline index (read-only)\n",
    "EXCEL_PATH = resolve_path(ROOT_DIR, cfg[\"paths\"][\"excel_path\"])       # optional depending on your notebook\n",
    "\n",
    "# Template (read-only)\n",
    "TEMPLATE_MD = resolve_path(\n",
    "    ROOT_DIR,\n",
    "    cfg[\"paths\"].get(\"template_md\", \"data/inputs/dmp-template.md\")\n",
    ")\n",
    "\n",
    "# ---------- RAG params ----------\n",
    "TOP_K = int(cfg[\"rag\"][\"retriever_top_k\"])\n",
    "\n",
    "# ---------- Models ----------\n",
    "EMBED_MODEL = cfg[\"models\"][\"embedding_model\"]\n",
    "LLM_MODEL   = cfg[\"models\"][\"llm_name\"]\n",
    "\n",
    "EMBED_DEVICE       = cfg[\"models\"][\"embedding_device\"]\n",
    "EMBED_BATCH_SIZE   = int(cfg[\"models\"][\"embedding_batch_size\"])\n",
    "NORMALIZE_EMBEDS   = bool(cfg[\"models\"][\"normalize_embeddings\"])\n",
    "HF_CACHE_DIR       = resolve_path(ROOT_DIR, cfg[\"models\"][\"hf_cache_dir\"])\n",
    "LOCAL_FILES_ONLY   = bool(cfg[\"models\"][\"local_files_only\"])\n",
    "ALLOW_DL_IF_MISS   = bool(cfg[\"models\"][\"allow_download_if_missing\"])\n",
    "\n",
    "# ---------- Notebook-only outputs (always under noteboo_DMP_RAG/) ----------\n",
    "OUTPUT_MD   = NB_MD_DIR / \"generated_dmp.md\"\n",
    "OUTPUT_DOCX = NB_DOCX_DIR / \"generated_dmp.docx\"\n",
    "\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def create_folder(folderpath: Path | str) -> None:\n",
    "    Path(folderpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_md(folderpath: Path | str, filename: str, text: str) -> Path:\n",
    "    create_folder(folderpath)\n",
    "    out_path = Path(folderpath) / filename\n",
    "    out_path.write_text(text, encoding=\"utf-8\")\n",
    "    print(\"Saved:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "def md_to_docs(md_filepath: Path | str, docx_folderpath: Path | str, docx_filename: str) -> Path:\n",
    "    create_folder(docx_folderpath)\n",
    "    out_path = Path(docx_folderpath) / docx_filename\n",
    "    pypandoc.convert_file(str(md_filepath), \"docx\", outputfile=str(out_path))\n",
    "    print(\"Converted:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "def clean_filename(name: str) -> str:\n",
    "    \"\"\"Remove illegal characters from filenames (Windows-safe).\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name)).strip()\n",
    "\n",
    "\n",
    "# ---------- Sanity print ----------\n",
    "print(\"STEP 1 ready (reuses pipeline index, notebook-local outputs)\")\n",
    "print(f\"CONFIG_YAML : {CONFIG_YAML}\")\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"ROOT_DIR    : {ROOT_DIR}\")\n",
    "print(f\"NOTEBOOK_DIR: {NOTEBOOK_DIR}\")\n",
    "print(f\"NB_OUT_ROOT : {NB_OUT_ROOT}\")\n",
    "print(f\"RUN_DIR     : {RUN_DIR}\")\n",
    "\n",
    "print(f\"INDEX_DIR (pipeline): {INDEX_DIR}\")\n",
    "print(f\"OUTPUT_MD (notebook): {OUTPUT_MD}\")\n",
    "print(f\"OUTPUT_DOCX(notebook): {OUTPUT_DOCX}\")\n",
    "\n",
    "print(f\"DATA_PDFS   : {DATA_PDFS}\")\n",
    "print(f\"EXCEL_PATH  : {EXCEL_PATH}\")\n",
    "print(f\"TEMPLATE_MD : {TEMPLATE_MD}\")\n",
    "\n",
    "print(f\"EMBED_MODEL : {EMBED_MODEL}\")\n",
    "print(f\"LLM_MODEL   : {LLM_MODEL}\")\n",
    "print(f\"TOP_K       : {TOP_K}\")\n",
    "print(f\"EMBED_DEVICE: {EMBED_DEVICE} | BATCH: {EMBED_BATCH_SIZE} | NORMALIZE: {NORMALIZE_EMBEDS}\")\n",
    "print(f\"HF_CACHE_DIR: {HF_CACHE_DIR} | local_files_only={LOCAL_FILES_ONLY} | allow_download_if_missing={ALLOW_DL_IF_MISS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc0461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1496.07it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index (read-only) from: C:\\Users\\Nahid\\dmpchef\\data\\vector_db\\NIH_sharing_db\n",
      "Retriever ready | top_k=6 | embed_model=sentence-transformers/all-MiniLM-L6-v2 | device=cuda | backend=langchain_huggingface\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 2 — Load pipeline FAISS index (READ-ONLY) and create retriever\n",
    "# ============================================\n",
    "from pathlib import Path\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Prefer new HuggingFace integration if installed; fallback to langchain_community\n",
    "try:\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings  # type: ignore\n",
    "    _EMB_BACKEND = \"langchain_huggingface\"\n",
    "except Exception:\n",
    "    from langchain_community.embeddings import HuggingFaceEmbeddings  # type: ignore\n",
    "    _EMB_BACKEND = \"langchain_community\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Ensure HF uses the same cache directory you configured (very important in notebooks)\n",
    "# This helps avoid \"couldn't find them in the cached files\" surprises.\n",
    "if HF_CACHE_DIR is not None:\n",
    "    os.environ.setdefault(\"HF_HOME\", str(HF_CACHE_DIR))\n",
    "\n",
    "def _pick_device(requested: str) -> str:\n",
    "    req = (requested or \"auto\").lower().strip()\n",
    "    if req in (\"auto\", \"cuda\"):\n",
    "        return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return \"cpu\"\n",
    "\n",
    "device = _pick_device(EMBED_DEVICE)\n",
    "\n",
    "def _make_embeddings(local_only: bool):\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=EMBED_MODEL,\n",
    "        cache_folder=str(HF_CACHE_DIR) if HF_CACHE_DIR is not None else None,\n",
    "        model_kwargs={\n",
    "            \"device\": device,\n",
    "            \"local_files_only\": bool(local_only),\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            \"batch_size\": int(EMBED_BATCH_SIZE),\n",
    "            \"normalize_embeddings\": bool(NORMALIZE_EMBEDS),\n",
    "        },\n",
    "    )\n",
    "\n",
    "# 1) Try per YAML: local_files_only\n",
    "try:\n",
    "    embeddings = _make_embeddings(local_only=LOCAL_FILES_ONLY)\n",
    "except Exception as e1:\n",
    "    # 2) If offline cache miss but allowed to download, retry online\n",
    "    if LOCAL_FILES_ONLY and ALLOW_DL_IF_MISS:\n",
    "        print(\"Embeddings not found in cache; retrying with download enabled...\")\n",
    "        embeddings = _make_embeddings(local_only=False)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "index_dir = Path(INDEX_DIR)\n",
    "faiss_path = index_dir / \"index.faiss\"\n",
    "pkl_path   = index_dir / \"index.pkl\"\n",
    "\n",
    "if not (faiss_path.exists() and pkl_path.exists()):\n",
    "    raise FileNotFoundError(\n",
    "        \"FAISS index files not found.\\n\"\n",
    "        f\"Expected:\\n- {faiss_path}\\n- {pkl_path}\\n\"\n",
    "        \"Run your pipeline build_index.py or fix config.paths.index_dir.\"\n",
    "    )\n",
    "\n",
    "print(\"Loading FAISS index (read-only) from:\", index_dir)\n",
    "vectorstore = FAISS.load_local(\n",
    "    str(index_dir),\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": int(TOP_K)})\n",
    "\n",
    "print(\n",
    "    \"Retriever ready\",\n",
    "    f\"top_k={TOP_K}\",\n",
    "    f\"embed_model={EMBED_MODEL}\",\n",
    "    f\"device={device}\",\n",
    "    f\"backend={_EMB_BACKEND}\",\n",
    "    sep=\" | \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ecf6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel loaded successfully: 26 rows\n",
      "DMP Markdown template loaded.\n",
      "RAG chain initialized with model: llama3.3:latest | few-shot examples: 3\n",
      "RAG chain ready for generation.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 3 — Load Excel + Template, Build Few-shot, and Build RAG Chain\n",
    "# ============================================\n",
    "import re\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# ---- Guard: Step 2 must run first ----\n",
    "if \"retriever\" not in globals():\n",
    "    raise RuntimeError(\"`retriever` is not defined. Run STEP 2 (load FAISS index) before STEP 3.\")\n",
    "\n",
    "# --- Load Excel file ---\n",
    "if EXCEL_PATH is None or not EXCEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Excel file not found: {EXCEL_PATH}\")\n",
    "\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.fillna(\"\")\n",
    "print(f\"Excel loaded successfully: {len(df)} rows\")\n",
    "\n",
    "# --- Load Markdown Template ---\n",
    "if TEMPLATE_MD is None or not TEMPLATE_MD.exists():\n",
    "    raise FileNotFoundError(f\"Template file not found: {TEMPLATE_MD}\")\n",
    "\n",
    "dmp_template_text = TEMPLATE_MD.read_text(encoding=\"utf-8\")\n",
    "print(\"DMP Markdown template loaded.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Few-shot builder from Excel (Element-aware + relevant)\n",
    "# ============================================================\n",
    "def _infer_element_from_question(q: str) -> str:\n",
    "    m = re.search(r\"element\\s*([1-6])\", q, flags=re.IGNORECASE)\n",
    "    return m.group(1) if m else \"1\"\n",
    "\n",
    "def _row_to_fewshot_example(row: pd.Series, element_num: str) -> str:\n",
    "    title = str(row.get(\"title\", \"\")).strip()\n",
    "    designation = str(row.get(\"designation\", \"\")).strip()\n",
    "\n",
    "    if element_num == \"1\":\n",
    "        a = str(row.get(\"element_1a\", \"\")).strip()\n",
    "        b = str(row.get(\"element_1b\", \"\")).strip()\n",
    "        c = str(row.get(\"element_1c\", \"\")).strip()\n",
    "        answer = (\n",
    "            \"**Element 1: Data Type**\\n\\n\"\n",
    "            \"1. **Types and amount of scientific data expected to be generated in the project:**\\n\"\n",
    "            f\"{a}\\n\\n\"\n",
    "            \"2. **Scientific data that will be preserved and shared, and the rationale for doing so:**\\n\"\n",
    "            f\"{b}\\n\\n\"\n",
    "            \"3. **Metadata, other relevant data, and associated documentation:**\\n\"\n",
    "            f\"{c}\"\n",
    "        )\n",
    "    elif element_num == \"2\":\n",
    "        answer = \"**Element 2: Related Tools, Software and/or Code**\\n\\n\" + str(row.get(\"element_2\", \"\")).strip()\n",
    "    elif element_num == \"3\":\n",
    "        answer = \"**Element 3: Standards**\\n\\n\" + str(row.get(\"element_3\", \"\")).strip()\n",
    "    elif element_num == \"4\":\n",
    "        a = str(row.get(\"element_4a\", \"\")).strip()\n",
    "        b = str(row.get(\"element_4b\", \"\")).strip()\n",
    "        c = str(row.get(\"element_4c\", \"\")).strip()\n",
    "        answer = (\n",
    "            \"**Element 4: Data Preservation, Access, and Associated Timelines**\\n\\n\"\n",
    "            \"1. **Repository and preservation timeline:**\\n\"\n",
    "            f\"{a}\\n\\n\"\n",
    "            \"2. **How data will be discoverable/findable:**\\n\"\n",
    "            f\"{b}\\n\\n\"\n",
    "            \"3. **Access, sharing mechanisms, and timelines:**\\n\"\n",
    "            f\"{c}\"\n",
    "        )\n",
    "    elif element_num == \"5\":\n",
    "        a = str(row.get(\"element_5a\", \"\")).strip()\n",
    "        b = str(row.get(\"element_5b\", \"\")).strip()\n",
    "        c = str(row.get(\"element_5c\", \"\")).strip()\n",
    "        answer = (\n",
    "            \"**Element 5: Access, Distribution, or Reuse Considerations**\\n\\n\"\n",
    "            \"1. **Factors affecting access/sharing:**\\n\"\n",
    "            f\"{a}\\n\\n\"\n",
    "            \"2. **Steps for access / distribution:**\\n\"\n",
    "            f\"{b}\\n\\n\"\n",
    "            \"3. **Privacy / confidentiality protections:**\\n\"\n",
    "            f\"{c}\"\n",
    "        )\n",
    "    else:  # 6\n",
    "        answer = \"**Element 6: Oversight of Data Management and Sharing**\\n\\n\" + str(row.get(\"element_6\", \"\")).strip()\n",
    "\n",
    "    q = f'Write Element {element_num} for a project similar to: \"{title}\" ({designation}).'\n",
    "    return f\"### Example\\nQuestion:\\n{q}\\n\\nAnswer:\\n{answer}\"\n",
    "\n",
    "def build_few_shot_block_from_excel(question: str, n_examples: int = 3) -> str:\n",
    "    element_num = _infer_element_from_question(question)\n",
    "\n",
    "    needed_cols = {\n",
    "        \"1\": [\"element_1a\", \"element_1b\", \"element_1c\"],\n",
    "        \"2\": [\"element_2\"],\n",
    "        \"3\": [\"element_3\"],\n",
    "        \"4\": [\"element_4a\", \"element_4b\", \"element_4c\"],\n",
    "        \"5\": [\"element_5a\", \"element_5b\", \"element_5c\"],\n",
    "        \"6\": [\"element_6\"],\n",
    "    }[element_num]\n",
    "\n",
    "    df_valid = df.copy()\n",
    "\n",
    "    missing = [c for c in needed_cols if c not in df_valid.columns]\n",
    "    if missing:\n",
    "        return \"\"\n",
    "\n",
    "    df_valid = df_valid[\n",
    "        (df_valid[needed_cols].astype(str).apply(lambda s: s.str.strip().ne(\"\")).all(axis=1))\n",
    "    ]\n",
    "    if df_valid.empty:\n",
    "        return \"\"\n",
    "\n",
    "    q_terms = set(re.findall(r\"[a-zA-Z]{3,}\", question.lower()))\n",
    "\n",
    "    def score_row(r: pd.Series) -> int:\n",
    "        hay = f\"{r.get('title','')} {r.get('designation','')} {r.get('institute','')} {r.get('consentdescription','')}\"\n",
    "        hay_terms = set(re.findall(r\"[a-zA-Z]{3,}\", str(hay).lower()))\n",
    "        return len(q_terms & hay_terms)\n",
    "\n",
    "    df_valid = df_valid.copy()\n",
    "    df_valid[\"__score\"] = df_valid.apply(score_row, axis=1)\n",
    "    df_top = df_valid.sort_values(\"__score\", ascending=False).head(n_examples)\n",
    "\n",
    "    examples = [_row_to_fewshot_example(row, element_num) for _, row in df_top.iterrows()]\n",
    "    return \"\\n\\n---\\n\\n\".join(examples)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Build RAG chain (Few-shot + RAG grounding)\n",
    "# ============================================\n",
    "def build_rag_chain(retriever, llm_model=LLM_MODEL, n_few_shot: int = 3):\n",
    "    llm = Ollama(model=llm_model)\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    def format_docs(docs):\n",
    "        if not docs:\n",
    "            return \"\"\n",
    "        formatted = []\n",
    "        for d in docs:\n",
    "            page = d.metadata.get(\"page\", d.metadata.get(\"page_number\", \"\"))\n",
    "            source = d.metadata.get(\"source\", d.metadata.get(\"file_path\", \"\"))\n",
    "            page_disp = (page + 1) if isinstance(page, int) else page\n",
    "            formatted.append(f\"[Page {page_disp}] {source}\\n{(d.page_content or '').strip()}\")\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "\n",
    "    def make_few_shot(q: str) -> str:\n",
    "        return build_few_shot_block_from_excel(q, n_examples=n_few_shot)\n",
    "\n",
    "    prompt_template = \"\"\"You are an expert biomedical data steward and grant writer.\n",
    "Create a high-quality NIH Data Management and Sharing Plan (DMSP) based on the retrieved NIH context and the user's query.\n",
    "\n",
    "You MUST follow the formatting and style demonstrated by the few-shot examples.\n",
    "\n",
    "---- Few-shot examples (from your Excel) ----\n",
    "{few_shot}\n",
    "\n",
    "---- Context from NIH Repository (grounding) ----\n",
    "{context}\n",
    "\n",
    "---- Question ----\n",
    "{question}\n",
    "\n",
    "Rules:\n",
    "- Use NIH context when relevant; do NOT invent policy details.\n",
    "- If a specific policy detail is not supported by the provided context, write: \"Not specified in provided NIH context.\"\n",
    "- Follow the NIH template structure and keep section titles unchanged when the template is provided.\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"few_shot\", \"context\", \"question\"])\n",
    "\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"few_shot\": RunnablePassthrough() | make_few_shot,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | parser\n",
    "    )\n",
    "\n",
    "    print(f\"RAG chain initialized with model: {llm_model} | few-shot examples: {n_few_shot}\")\n",
    "    return rag_chain\n",
    "\n",
    "\n",
    "rag_chain = build_rag_chain(retriever, n_few_shot=3)\n",
    "print(\"RAG chain ready for generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "308a44de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook output folders:\n",
      "RUN_DIR    : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\n",
      "MD folder  : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\n",
      "DOCX folder: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\n",
      "LOG CSV    : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\rag_generated_dmp_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating DMP for: Clinical and MRI data from human research participants\n",
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Clinical and MRI data from human research participants.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:   4%|▍         | 1/26 [00:55<23:05, 55.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Clinical and MRI data from human research participants.docx\n",
      "\n",
      "Generating DMP for: Genomic data from human research participants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:   8%|▊         | 2/26 [01:51<22:12, 55.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Genomic data from human research participants.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Genomic data from human research participants.docx\n",
      "\n",
      "Generating DMP for: Genomic data from a non-human source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  12%|█▏        | 3/26 [02:47<21:29, 56.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Genomic data from a non-human source.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Genomic data from a non-human source.docx\n",
      "\n",
      "Generating DMP for: Secondary data analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  15%|█▌        | 4/26 [03:43<20:30, 55.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Secondary data analysis.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Secondary data analysis.docx\n",
      "\n",
      "Generating DMP for: Human clinical and genomics data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  19%|█▉        | 5/26 [04:40<19:42, 56.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Human clinical and genomics data.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Human clinical and genomics data.docx\n",
      "\n",
      "Generating DMP for: Gene expression analysis data from non-human model organism (zebrafish)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  23%|██▎       | 6/26 [05:54<20:48, 62.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Gene expression analysis data from non-human model organism (zebrafish).md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Gene expression analysis data from non-human model organism (zebrafish).docx\n",
      "\n",
      "Generating DMP for: Human survey data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  27%|██▋       | 7/26 [06:57<19:50, 62.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Human survey data.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Human survey data.docx\n",
      "\n",
      "Generating DMP for: Clinical Data from Human Research Participants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  31%|███       | 8/26 [07:54<18:10, 60.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Clinical Data from Human Research Participants.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Clinical Data from Human Research Participants.docx\n",
      "\n",
      "Generating DMP for: Human genomic data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  35%|███▍      | 9/26 [09:06<18:13, 64.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Human genomic data.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Human genomic data.docx\n",
      "\n",
      "Generating DMP for: Technology development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  38%|███▊      | 10/26 [10:19<17:52, 67.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Technology development.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Technology development.docx\n",
      "\n",
      "Generating DMP for: Basic Research from a Non-Human Source Example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  42%|████▏     | 11/26 [11:21<16:23, 65.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Basic Research from a Non-Human Source Example.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Basic Research from a Non-Human Source Example.docx\n",
      "\n",
      "Generating DMP for: Secondary Data Analysis Example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  46%|████▌     | 12/26 [12:16<14:30, 62.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Secondary Data Analysis Example.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Secondary Data Analysis Example.docx\n",
      "\n",
      "Generating DMP for: Survey and Interview Example\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  50%|█████     | 13/26 [13:11<13:01, 60.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Survey and Interview Example.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Survey and Interview Example.docx\n",
      "\n",
      "Generating DMP for: Human Clinical Trial Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  54%|█████▍    | 14/26 [14:11<12:01, 60.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Human Clinical Trial Data.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Human Clinical Trial Data.docx\n",
      "\n",
      "Generating DMP for: Clinical data from human research participants-NIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  58%|█████▊    | 15/26 [15:03<10:32, 57.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Clinical data from human research participants-NIA.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Clinical data from human research participants-NIA.docx\n",
      "\n",
      "Generating DMP for: Survey, interview, and biological data (tiered access)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  62%|██████▏   | 16/26 [15:57<09:26, 56.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Survey, interview, and biological data (tiered access).md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Survey, interview, and biological data (tiered access).docx\n",
      "\n",
      "Generating DMP for: Non-human data (primates)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  65%|██████▌   | 17/26 [16:47<08:09, 54.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Non-human data (primates).md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Non-human data (primates).docx\n",
      "\n",
      "Generating DMP for: Secondary data analysis-NIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  69%|██████▉   | 18/26 [17:51<07:40, 57.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Secondary data analysis-NIA.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Secondary data analysis-NIA.docx\n",
      "\n",
      "Generating DMP for: Survey and interview data-NIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  73%|███████▎  | 19/26 [18:44<06:31, 55.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Survey and interview data-NIA.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Survey and interview data-NIA.docx\n",
      "\n",
      "Generating DMP for: Human clinical and genomic data-NIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  77%|███████▋  | 20/26 [20:03<06:18, 63.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Human clinical and genomic data-NIA.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Human clinical and genomic data-NIA.docx\n",
      "\n",
      "Generating DMP for: Non-human data (rodents)-NIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  81%|████████  | 21/26 [21:20<05:36, 67.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Non-human data (rodents)-NIA.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Non-human data (rodents)-NIA.docx\n",
      "\n",
      "Generating DMP for: Clinical data (human biospecimens)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  85%|████████▍ | 22/26 [22:22<04:22, 65.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Clinical data (human biospecimens).md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Clinical data (human biospecimens).docx\n",
      "\n",
      "Generating DMP for: Drug discovery including intellectual property\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  88%|████████▊ | 23/26 [23:28<03:17, 65.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Drug discovery including intellectual property.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Drug discovery including intellectual property.docx\n",
      "\n",
      "Generating DMP for: HeLa Cell Whole Genome Sequence (DNA or RNA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  92%|█████████▏| 24/26 [24:35<02:12, 66.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\HeLa Cell Whole Genome Sequence (DNA or RNA).md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\HeLa Cell Whole Genome Sequence (DNA or RNA).docx\n",
      "\n",
      "Generating DMP for: Secondary Data Analysis on Data from Human Subjects-NIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs:  96%|█████████▌| 25/26 [25:37<01:04, 64.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Secondary Data Analysis on Data from Human Subjects-NIA.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Secondary Data Analysis on Data from Human Subjects-NIA.docx\n",
      "\n",
      "Generating DMP for: Analysis of social media posts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating NIH DMPs: 100%|██████████| 26/26 [26:41<00:00, 61.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md\\Analysis of social media posts.md\n",
      "Converted: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\docx\\Analysis of social media posts.docx\n",
      "\n",
      "Finished processing all rows.\n",
      "CSV log saved to: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\rag_generated_dmp_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 4 — RAG-Based DMP Generation (Notebook-safe, no icons)\n",
    "# Writes ONLY under: Output_7/run_*/ (from STEP 1)\n",
    "# Reuses: df, dmp_template_text, rag_chain (from STEP 3)\n",
    "# ============================================\n",
    "import re\n",
    "import pandas as pd\n",
    "import pypandoc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- Ensure notebook output folders exist ----------\n",
    "for p in [NB_OUT_ROOT, RUN_DIR, NB_MD_DIR, NB_DOCX_DIR]:\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Output log (inside the same run folder) ----------\n",
    "OUTPUT_LOG = RUN_DIR / \"rag_generated_dmp_log.csv\"\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def sanitize_filename(name: str, max_len: int = 140) -> str:\n",
    "    \"\"\"\n",
    "    Windows-safe filename:\n",
    "    - remove illegal characters\n",
    "    - collapse whitespace\n",
    "    - limit length to avoid long-path issues\n",
    "    \"\"\"\n",
    "    s = re.sub(r'[\\\\/*?:\"<>|]', \"_\", str(name).strip())\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    if len(s) > max_len:\n",
    "        s = s[:max_len].rstrip()\n",
    "    return s or \"untitled\"\n",
    "\n",
    "def save_md(folderpath: Path, filename: str, text: str) -> Path:\n",
    "    folderpath.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = folderpath / filename\n",
    "    out_path.write_text(text, encoding=\"utf-8\")\n",
    "    print(\"Saved:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "def md_to_docx(md_filepath: Path, docx_folder: Path, docx_filename: str) -> Path:\n",
    "    docx_folder.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = docx_folder / docx_filename\n",
    "    pypandoc.convert_file(str(md_filepath), \"docx\", outputfile=str(out_path))\n",
    "    print(\"Converted:\", out_path)\n",
    "    return out_path\n",
    "\n",
    "# ---------- Guards ----------\n",
    "if \"rag_chain\" not in globals():\n",
    "    raise RuntimeError(\"rag_chain not found. Run STEP 2 (retriever) + STEP 3 (rag_chain) first.\")\n",
    "if \"df\" not in globals():\n",
    "    raise RuntimeError(\"df not found. Run STEP 3 (Excel load) first.\")\n",
    "if \"dmp_template_text\" not in globals():\n",
    "    raise RuntimeError(\"dmp_template_text not found. Run STEP 3 (template load) first.\")\n",
    "\n",
    "print(\"Notebook output folders:\")\n",
    "print(\"RUN_DIR    :\", RUN_DIR)\n",
    "print(\"MD folder  :\", NB_MD_DIR)\n",
    "print(\"DOCX folder:\", NB_DOCX_DIR)\n",
    "print(\"LOG CSV    :\", OUTPUT_LOG)\n",
    "\n",
    "# ---------- Main generation ----------\n",
    "records = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating NIH DMPs\"):\n",
    "    title = str(row.get(\"title\", \"\")).strip()\n",
    "    if not title:\n",
    "        continue\n",
    "\n",
    "    print(\"\\nGenerating DMP for:\", title)\n",
    "\n",
    "    # Build proposal details from the row (only element* columns)\n",
    "    element_cols = [c for c in df.columns if str(c).startswith(\"element\")]\n",
    "    element_texts = []\n",
    "    for col in element_cols:\n",
    "        val = str(row.get(col, \"\")).strip()\n",
    "        if val:\n",
    "            element_texts.append(f\"{col.upper()}: {val}\")\n",
    "    query_data = \"\\n\".join(element_texts).strip()\n",
    "\n",
    "    # Build question for rag_chain (retrieval + few-shot happens inside chain)\n",
    "    question = f\"\"\"\n",
    "Create a complete NIH Data Management and Sharing Plan (DMSP) for the project titled: \"{title}\".\n",
    "\n",
    "Use the NIH DMSP Markdown template below and DO NOT change section titles.\n",
    "\n",
    "Project background / proposal details:\n",
    "{query_data}\n",
    "\n",
    "NIH DMSP Markdown template:\n",
    "{dmp_template_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.invoke(question)\n",
    "\n",
    "        safe_title = sanitize_filename(title)\n",
    "        md_filename = f\"{safe_title}.md\"\n",
    "        docx_filename = f\"{safe_title}.docx\"\n",
    "\n",
    "        md_path = save_md(NB_MD_DIR, md_filename, response)\n",
    "        docx_path = md_to_docx(md_path, NB_DOCX_DIR, docx_filename)\n",
    "\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"MD_Path\": str(md_path),\n",
    "            \"DOCX_Path\": str(docx_path),\n",
    "            \"Question_Preview\": question[:1000],\n",
    "            \"Generated_DMP_Preview\": response[:1000],\n",
    "            \"Error\": \"\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error generating DMP for:\", title, \"|\", str(e))\n",
    "        records.append({\n",
    "            \"Title\": title,\n",
    "            \"MD_Path\": \"\",\n",
    "            \"DOCX_Path\": \"\",\n",
    "            \"Question_Preview\": question[:1000],\n",
    "            \"Generated_DMP_Preview\": \"\",\n",
    "            \"Error\": str(e)\n",
    "        })\n",
    "\n",
    "# ---------- Save log ----------\n",
    "pd.DataFrame(records).to_csv(OUTPUT_LOG, index=False, encoding=\"utf-8\")\n",
    "print(\"\\nFinished processing all rows.\")\n",
    "print(\"CSV log saved to:\", OUTPUT_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "720e7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold PDF folder     : C:\\Users\\Nahid\\dmpchef\\data\\inputs\\gold_dmps | exists= True\n",
      "Generated MD folder : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md | exists= True\n",
      "Evaluation output   : c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\evaluation_results\n",
      "Found generated .md files: 26\n",
      "Found gold .pdf files    : 26\n",
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1716.61it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready.\n",
      "Indexed generated DMPs: 26\n",
      "Indexed gold PDFs     : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching & Comparing DMPs: 100%|██████████| 26/26 [00:05<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\evaluation_results\\full_dmp_pdf_comparison_fuzzy.csv\n",
      "Total matched DMP pairs: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 5 — Full DMP Comparison: Markdown (Generated) vs PDF (Gold, Fuzzy Matching)\n",
    "# Notebook-safe , and writes results ONLY under your current RUN_DIR\n",
    "# Uses:\n",
    "#   - NB_MD_DIR (generated .md from STEP 4)\n",
    "#   - RUN_DIR   (evaluation output folder)\n",
    "# You set GOLD_DIR manually (PDF gold folder)\n",
    "# ============================================\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths (Notebook-safe)\n",
    "# ------------------------------------------------------------\n",
    "# 1) Generated markdown comes from the current run folder (STEP 4)\n",
    "GENERATED_DIR = Path(NB_MD_DIR)\n",
    "\n",
    "# 2) Gold PDFs: set your correct folder here\n",
    "#    Examples you can try (uncomment the one that matches your repo):\n",
    "# GOLD_DIR = ROOT_DIR / \"data\" / \"inputs\" / \"gold_dmps\"\n",
    "# GOLD_DIR = ROOT_DIR / \"data\" / \"gold_dmps\"\n",
    "GOLD_DIR = ROOT_DIR / \"data\" / \"inputs\" / \"gold_dmps\"\n",
    "\n",
    "# 3) Evaluation output: store under this run\n",
    "EVAL_DIR = Path(RUN_DIR) / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Gold PDF folder     :\", GOLD_DIR,   \"| exists=\", GOLD_DIR.exists())\n",
    "print(\"Generated MD folder :\", GENERATED_DIR, \"| exists=\", GENERATED_DIR.exists())\n",
    "print(\"Evaluation output   :\", EVAL_DIR)\n",
    "\n",
    "gold_pdf_count = len(list(GOLD_DIR.glob(\"*.pdf\"))) if GOLD_DIR.exists() else 0\n",
    "gen_md_count   = len(list(GENERATED_DIR.glob(\"*.md\"))) if GENERATED_DIR.exists() else 0\n",
    "print(\"Found generated .md files:\", gen_md_count)\n",
    "print(\"Found gold .pdf files    :\", gold_pdf_count)\n",
    "\n",
    "if gen_md_count == 0:\n",
    "    raise FileNotFoundError(f\"No generated Markdown files found in: {GENERATED_DIR}\")\n",
    "if gold_pdf_count == 0:\n",
    "    raise FileNotFoundError(f\"No gold PDF files found in: {GOLD_DIR}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Models\n",
    "# ------------------------------------------------------------\n",
    "print(\"Loading models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"Models ready.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------------------\n",
    "def normalize_name(name: str) -> str:\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # remove special tags some LLMs produce\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "    # remove markdown formatting\n",
    "    text = re.sub(r\"#+\\s*\", \"\", text)\n",
    "    text = re.sub(r\"\\*\\*|\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    txt = \"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                txt += page.get_text(\"text\") + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(\"Error reading PDF:\", pdf_path.name, \"|\", str(e))\n",
    "    return clean_text(txt)\n",
    "\n",
    "def chunk_text(text: str, size: int = 300) -> list[str]:\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "def compare_chunked(gold_text: str, gen_text: str, model) -> tuple[float, float]:\n",
    "    gold_chunks = chunk_text(gold_text)\n",
    "    gen_chunks  = chunk_text(gen_text)\n",
    "\n",
    "    sbert_scores = []\n",
    "    rouge_scores = []\n",
    "\n",
    "    # Pre-embed generated chunks once (much faster)\n",
    "    gen_embs = model.encode(gen_chunks, convert_to_tensor=True) if gen_chunks else None\n",
    "\n",
    "    for g in gold_chunks:\n",
    "        emb_g = model.encode(g, convert_to_tensor=True)\n",
    "\n",
    "        # SBERT max similarity over generated chunks\n",
    "        if gen_embs is not None and len(gen_chunks) > 0:\n",
    "            sims = util.cos_sim(emb_g, gen_embs)[0].cpu().numpy()\n",
    "            sbert_scores.append(float(np.max(sims)))\n",
    "        else:\n",
    "            sbert_scores.append(0.0)\n",
    "\n",
    "        # ROUGE-L max recall over generated chunks\n",
    "        if gen_chunks:\n",
    "            rouge_chunk_scores = [rouge.score(g, gg)[\"rougeL\"].recall for gg in gen_chunks]\n",
    "            rouge_scores.append(float(np.max(rouge_chunk_scores)))\n",
    "        else:\n",
    "            rouge_scores.append(0.0)\n",
    "\n",
    "    return float(np.mean(sbert_scores)), float(np.mean(rouge_scores))\n",
    "\n",
    "def best_fuzzy_match(target: str, gold_names: list[str], threshold: float = 0.6) -> tuple[str | None, float]:\n",
    "    best_match, best_score = None, 0.0\n",
    "    for g in gold_names:\n",
    "        score = SequenceMatcher(None, target, g).ratio()\n",
    "        if score > best_score:\n",
    "            best_match, best_score = g, score\n",
    "    return (best_match, best_score) if best_score >= threshold else (None, best_score)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Collect files\n",
    "# ------------------------------------------------------------\n",
    "gold_files = {normalize_name(f.stem): f for f in GOLD_DIR.glob(\"*.pdf\")}\n",
    "gen_files  = {normalize_name(f.stem): f for f in GENERATED_DIR.glob(\"*.md\")}\n",
    "print(\"Indexed generated DMPs:\", len(gen_files))\n",
    "print(\"Indexed gold PDFs     :\", len(gold_files))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compare\n",
    "# ------------------------------------------------------------\n",
    "results = []\n",
    "gold_keys = list(gold_files.keys())\n",
    "\n",
    "for name, gen_path in tqdm(gen_files.items(), desc=\"Matching & Comparing DMPs\"):\n",
    "    best_match, match_score = best_fuzzy_match(name, gold_keys, threshold=0.6)\n",
    "    if not best_match:\n",
    "        continue\n",
    "\n",
    "    gold_path = gold_files[best_match]\n",
    "\n",
    "    gold_text = extract_text_from_pdf(gold_path)\n",
    "    gen_text  = clean_text(gen_path.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
    "\n",
    "    if not gold_text or not gen_text:\n",
    "        continue\n",
    "\n",
    "    sbert_sim, rouge_l = compare_chunked(gold_text, gen_text, sbert)\n",
    "\n",
    "    results.append({\n",
    "        \"Generated_File\": gen_path.name,\n",
    "        \"Matched_Gold_PDF\": gold_path.name,\n",
    "        \"Match_Score\": round(match_score, 3),\n",
    "        \"SBERT_Similarity\": round(sbert_sim, 4),\n",
    "        \"ROUGE_L_Recall\": round(rouge_l, 4),\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "out_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "df_results.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nResults saved to:\", out_path)\n",
    "print(\"Total matched DMP pairs:\", len(df_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b15824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold Excel: C:\\Users\\Nahid\\dmpchef\\data\\inputs\\inputs.xlsx | exists= True\n",
      "Generated MD folder: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\md | exists= True\n",
      "Eval output folder: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\evaluation_results\n",
      "Found generated Markdown files: 26\n",
      "Loaded gold projects: 26\n",
      "Gold element columns used: ['element_1a', 'element_1b', 'element_1c', 'element_2', 'element_3', 'element_4a', 'element_4b', 'element_4c', 'element_5a', 'element_5b', 'element_5c', 'element_6']\n",
      "Loading evaluation models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1565.33it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing element-level: 100%|██████████| 26/26 [00:01<00:00, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Element-level similarity saved to: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\evaluation_results\\element_similarity_exact_titles.csv\n",
      "Total element–section best matches: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 6 — Element-Level Comparison with Gold Standard \n",
    "# Compares: generated Markdown sections (NB_MD_DIR) vs gold Excel element fields\n",
    "# Writes:   RUN_DIR/evaluation_results/element_similarity_exact_titles.csv\n",
    "# ============================================\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths (Notebook-safe; reuse STEP 1 variables)\n",
    "# ------------------------------------------------------------\n",
    "# Generated markdown from current run\n",
    "GENERATED_DIR = Path(NB_MD_DIR)\n",
    "\n",
    "# Gold Excel: your reference file (same Excel you used to generate)\n",
    "GOLD_PATH = Path(EXCEL_PATH)  # from STEP 1\n",
    "\n",
    "# Evaluation output goes inside this run folder\n",
    "EVAL_DIR = Path(RUN_DIR) / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Gold Excel:\", GOLD_PATH, \"| exists=\", GOLD_PATH.exists())\n",
    "print(\"Generated MD folder:\", GENERATED_DIR, \"| exists=\", GENERATED_DIR.exists())\n",
    "print(\"Eval output folder:\", EVAL_DIR)\n",
    "\n",
    "if not GOLD_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Gold Excel not found: {GOLD_PATH}\")\n",
    "if not GENERATED_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Generated Markdown folder not found: {GENERATED_DIR}\")\n",
    "\n",
    "md_files = sorted(GENERATED_DIR.glob(\"*.md\"))\n",
    "print(\"Found generated Markdown files:\", len(md_files))\n",
    "if not md_files:\n",
    "    raise FileNotFoundError(f\"No .md files found in: {GENERATED_DIR}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load gold reference (Excel)\n",
    "# ------------------------------------------------------------\n",
    "df_gold = pd.read_excel(GOLD_PATH)\n",
    "df_gold.columns = df_gold.columns.str.strip().str.lower()\n",
    "df_gold = df_gold.fillna(\"\").astype(str)\n",
    "\n",
    "def normalize_title(name: str) -> str:\n",
    "    name = str(name).lower()\n",
    "    name = re.sub(r\"[^a-z0-9\\s]\", \" \", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name.strip()\n",
    "\n",
    "if \"title\" not in df_gold.columns:\n",
    "    raise KeyError(\"Gold Excel must contain a 'title' column.\")\n",
    "\n",
    "df_gold[\"title_norm\"] = df_gold[\"title\"].apply(normalize_title)\n",
    "\n",
    "gold_elements = [\n",
    "    \"element_1a\",\"element_1b\",\"element_1c\",\n",
    "    \"element_2\",\"element_3\",\n",
    "    \"element_4a\",\"element_4b\",\"element_4c\",\n",
    "    \"element_5a\",\"element_5b\",\"element_5c\",\n",
    "    \"element_6\"\n",
    "]\n",
    "gold_elements = [c for c in gold_elements if c in df_gold.columns]\n",
    "\n",
    "print(\"Loaded gold projects:\", len(df_gold))\n",
    "print(\"Gold element columns used:\", gold_elements)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Models\n",
    "# ------------------------------------------------------------\n",
    "print(\"Loading evaluation models...\")\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "print(\"Models ready.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Markdown parsing helpers\n",
    "# ------------------------------------------------------------\n",
    "def is_title(line: str) -> bool:\n",
    "    s = line.strip()\n",
    "    # Markdown headers OR numbered bold titles like: 1. **Data Types**\n",
    "    return s.startswith(\"#\") or bool(re.match(r\"^\\s*\\d*\\.?\\s*\\*\\*.*\\*\\*\\s*$\", s))\n",
    "\n",
    "def strip_llm_noise(text: str) -> str:\n",
    "    text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "    return text\n",
    "\n",
    "def extract_sections(md_path: Path) -> pd.DataFrame:\n",
    "    text = md_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    text = strip_llm_noise(text)\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    entries, current_title, buf = [], None, []\n",
    "\n",
    "    for ln in lines:\n",
    "        if is_title(ln):\n",
    "            if current_title and any(x.strip() for x in buf):\n",
    "                entries.append({\n",
    "                    \"Section Title\": current_title.strip(),\n",
    "                    \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "                })\n",
    "            current_title, buf = ln, []\n",
    "        else:\n",
    "            buf.append(ln)\n",
    "\n",
    "    if current_title and any(x.strip() for x in buf):\n",
    "        entries.append({\n",
    "            \"Section Title\": current_title.strip(),\n",
    "            \"Generated Content\": \"\\n\".join(buf).strip()\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compare (exact normalized title match)\n",
    "# ------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "# Pre-index gold rows by normalized title for fast lookup\n",
    "gold_by_title = {r[\"title_norm\"]: r for _, r in df_gold.iterrows()}\n",
    "\n",
    "for md_file in tqdm(md_files, desc=\"Comparing element-level\"):\n",
    "    gen_title_raw = md_file.stem\n",
    "    gen_title_norm = normalize_title(gen_title_raw)\n",
    "\n",
    "    gold_row = gold_by_title.get(gen_title_norm)\n",
    "    if gold_row is None:\n",
    "        continue\n",
    "\n",
    "    gold_title = gold_row[\"title\"]\n",
    "\n",
    "    # Collect non-empty gold element texts\n",
    "    gold_texts = {e: str(gold_row.get(e, \"\")).strip() for e in gold_elements}\n",
    "    gold_texts = {k: v for k, v in gold_texts.items() if v}\n",
    "\n",
    "    if not gold_texts:\n",
    "        continue\n",
    "\n",
    "    # Extract generated sections\n",
    "    gen_df = extract_sections(md_file)\n",
    "    if gen_df.empty:\n",
    "        continue\n",
    "\n",
    "    # Clean sections and drop empties\n",
    "    gen_df[\"Generated Content\"] = gen_df[\"Generated Content\"].astype(str).str.strip()\n",
    "    gen_df = gen_df[gen_df[\"Generated Content\"].str.len() > 0]\n",
    "    if gen_df.empty:\n",
    "        continue\n",
    "\n",
    "    # Embed all generated sections once (speedup)\n",
    "    section_texts = gen_df[\"Generated Content\"].tolist()\n",
    "    section_embs = sbert.encode(section_texts, convert_to_tensor=True)\n",
    "\n",
    "    for element, gold_text in gold_texts.items():\n",
    "        emb_gold = sbert.encode(gold_text, convert_to_tensor=True)\n",
    "\n",
    "        sims = util.cos_sim(emb_gold, section_embs)[0].cpu().numpy()\n",
    "        best_idx = int(np.argmax(sims))\n",
    "        best_sbert = float(sims[best_idx])\n",
    "\n",
    "        best_section_title = gen_df.iloc[best_idx][\"Section Title\"]\n",
    "        best_section_text  = gen_df.iloc[best_idx][\"Generated Content\"]\n",
    "        best_rouge = float(rouge.score(gold_text, best_section_text)[\"rougeL\"].recall)\n",
    "\n",
    "        results.append({\n",
    "            \"Gold Project\": gold_title,\n",
    "            \"Gold Element\": element,\n",
    "            \"Generated File\": md_file.name,\n",
    "            \"Best Generated Section Title\": best_section_title,\n",
    "            \"SBERT_Similarity\": round(best_sbert, 4),\n",
    "            \"ROUGE_L_Recall\": round(best_rouge, 4),\n",
    "        })\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Save\n",
    "# ------------------------------------------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "out_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "df_results.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nElement-level similarity saved to:\", out_path)\n",
    "print(\"Total element–section best matches:\", len(df_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979d77ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_DIR: c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\evaluation_results\n",
      "Loaded full-document rows: 26\n",
      "Loaded element-level rows: 312\n",
      "\n",
      "Full-document summary (mean by Generated_File):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_File</th>\n",
       "      <th>SBERT_mean</th>\n",
       "      <th>ROUGE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysis of social media posts.md</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>0.3989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic Research from a Non-Human Source Example.md</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>0.4157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Data from Human Research Participants.md</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.2588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical and MRI data from human research part...</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.2736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical data (human biospecimens).md</td>\n",
       "      <td>0.7663</td>\n",
       "      <td>0.3719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical data from human research participants...</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.4077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drug discovery including intellectual property.md</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>0.3616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gene expression analysis data from non-human m...</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>0.6365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genomic data from a non-human source.md</td>\n",
       "      <td>0.7218</td>\n",
       "      <td>0.2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Genomic data from human research participants.md</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HeLa Cell Whole Genome Sequence (DNA or RNA).md</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Human Clinical Trial Data.md</td>\n",
       "      <td>0.6701</td>\n",
       "      <td>0.2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human clinical and genomic data-NIA.md</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human clinical and genomics data.md</td>\n",
       "      <td>0.7136</td>\n",
       "      <td>0.4509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human genomic data.md</td>\n",
       "      <td>0.6524</td>\n",
       "      <td>0.3227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human survey data.md</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.3334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Non-human data (primates).md</td>\n",
       "      <td>0.7348</td>\n",
       "      <td>0.4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Non-human data (rodents)-NIA.md</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.6695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Secondary Data Analysis Example.md</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Secondary Data Analysis on Data from Human Sub...</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.3410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Secondary data analysis-NIA.md</td>\n",
       "      <td>0.7734</td>\n",
       "      <td>0.2954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Secondary data analysis.md</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Survey and Interview Example.md</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>0.2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Survey and interview data-NIA.md</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.4715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Survey, interview, and biological data (tiered...</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.4398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Technology development.md</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.6794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Generated_File  SBERT_mean  ROUGE_mean\n",
       "0                   Analysis of social media posts.md      0.7950      0.3989\n",
       "1   Basic Research from a Non-Human Source Example.md      0.7952      0.4157\n",
       "2   Clinical Data from Human Research Participants.md      0.6871      0.2588\n",
       "3   Clinical and MRI data from human research part...      0.7133      0.2736\n",
       "4               Clinical data (human biospecimens).md      0.7663      0.3719\n",
       "5   Clinical data from human research participants...      0.7751      0.4077\n",
       "6   Drug discovery including intellectual property.md      0.7858      0.3616\n",
       "7   Gene expression analysis data from non-human m...      0.8322      0.6365\n",
       "8             Genomic data from a non-human source.md      0.7218      0.2704\n",
       "9    Genomic data from human research participants.md      0.7095      0.2703\n",
       "10    HeLa Cell Whole Genome Sequence (DNA or RNA).md      0.8650      0.6086\n",
       "11                       Human Clinical Trial Data.md      0.6701      0.2542\n",
       "12             Human clinical and genomic data-NIA.md      0.8125      0.5415\n",
       "13                Human clinical and genomics data.md      0.7136      0.4509\n",
       "14                              Human genomic data.md      0.6524      0.3227\n",
       "15                               Human survey data.md      0.7286      0.3334\n",
       "16                       Non-human data (primates).md      0.7348      0.4436\n",
       "17                    Non-human data (rodents)-NIA.md      0.8779      0.6695\n",
       "18                 Secondary Data Analysis Example.md      0.7845      0.3696\n",
       "19  Secondary Data Analysis on Data from Human Sub...      0.7990      0.3410\n",
       "20                     Secondary data analysis-NIA.md      0.7734      0.2954\n",
       "21                         Secondary data analysis.md      0.6497      0.2809\n",
       "22                    Survey and Interview Example.md      0.6998      0.2864\n",
       "23                   Survey and interview data-NIA.md      0.7763      0.4715\n",
       "24  Survey, interview, and biological data (tiered...      0.8069      0.4398\n",
       "25                          Technology development.md      0.6808      0.6794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall full-document means:\n",
      "{'SBERT_overall_mean': 0.7541, 'ROUGE_overall_mean': 0.4020692307692307}\n",
      "\n",
      "Element-level summary (mean ± sd):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Element</th>\n",
       "      <th>SBERT_mean_sd</th>\n",
       "      <th>ROUGE_mean_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>element_1a</td>\n",
       "      <td>0.84 ± 0.16</td>\n",
       "      <td>0.55 ± 0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>element_1b</td>\n",
       "      <td>0.79 ± 0.14</td>\n",
       "      <td>0.56 ± 0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>element_1c</td>\n",
       "      <td>0.82 ± 0.13</td>\n",
       "      <td>0.57 ± 0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>element_2</td>\n",
       "      <td>0.85 ± 0.10</td>\n",
       "      <td>0.56 ± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>element_3</td>\n",
       "      <td>0.81 ± 0.15</td>\n",
       "      <td>0.50 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>element_4a</td>\n",
       "      <td>0.83 ± 0.10</td>\n",
       "      <td>0.59 ± 0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>element_4b</td>\n",
       "      <td>0.86 ± 0.12</td>\n",
       "      <td>0.60 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>element_4c</td>\n",
       "      <td>0.88 ± 0.09</td>\n",
       "      <td>0.63 ± 0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>element_5a</td>\n",
       "      <td>0.77 ± 0.16</td>\n",
       "      <td>0.51 ± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>element_5b</td>\n",
       "      <td>0.83 ± 0.12</td>\n",
       "      <td>0.54 ± 0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>element_5c</td>\n",
       "      <td>0.83 ± 0.15</td>\n",
       "      <td>0.56 ± 0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>element_6</td>\n",
       "      <td>0.89 ± 0.08</td>\n",
       "      <td>0.64 ± 0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Element SBERT_mean_sd ROUGE_mean_sd\n",
       "0   element_1a   0.84 ± 0.16   0.55 ± 0.37\n",
       "1   element_1b   0.79 ± 0.14   0.56 ± 0.34\n",
       "2   element_1c   0.82 ± 0.13   0.57 ± 0.37\n",
       "3    element_2   0.85 ± 0.10   0.56 ± 0.31\n",
       "4    element_3   0.81 ± 0.15   0.50 ± 0.32\n",
       "5   element_4a   0.83 ± 0.10   0.59 ± 0.30\n",
       "6   element_4b   0.86 ± 0.12   0.60 ± 0.32\n",
       "7   element_4c   0.88 ± 0.09   0.63 ± 0.30\n",
       "8   element_5a   0.77 ± 0.16   0.51 ± 0.31\n",
       "9   element_5b   0.83 ± 0.12   0.54 ± 0.32\n",
       "10  element_5c   0.83 ± 0.15   0.56 ± 0.35\n",
       "11   element_6   0.89 ± 0.08   0.64 ± 0.30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved formatted tables:\n",
      "c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\evaluation_results\\summary_full_table_mean_only.csv\n",
      "c:\\Users\\Nahid\\dmpchef\\notebook_DMP_RAG\\Output_7\\run_20260220_092117\\evaluation_results\\summary_element_table_mean_sd.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 7 — Summarize Evaluation Results \n",
    "# Reads results from:\n",
    "#   RUN_DIR/evaluation_results/full_dmp_pdf_comparison_fuzzy.csv\n",
    "#   RUN_DIR/evaluation_results/element_similarity_exact_titles.csv\n",
    "# Writes summaries to the same folder.\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Notebook-safe eval directory (from STEP 1)\n",
    "# ------------------------------------------------------------\n",
    "EVAL_DIR = Path(RUN_DIR) / \"evaluation_results\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"EVAL_DIR:\", EVAL_DIR)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load CSVs (fail loudly if missing)\n",
    "# ------------------------------------------------------------\n",
    "full_path = EVAL_DIR / \"full_dmp_pdf_comparison_fuzzy.csv\"\n",
    "elem_path = EVAL_DIR / \"element_similarity_exact_titles.csv\"\n",
    "\n",
    "if not full_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {full_path} (Run STEP 5 first)\")\n",
    "if not elem_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {elem_path} (Run STEP 6 first)\")\n",
    "\n",
    "df_full = pd.read_csv(full_path)\n",
    "df_elem = pd.read_csv(elem_path)\n",
    "\n",
    "print(\"Loaded full-document rows:\", len(df_full))\n",
    "print(\"Loaded element-level rows:\", len(df_elem))\n",
    "\n",
    "if df_full.empty:\n",
    "    raise ValueError(\"full_dmp_pdf_comparison_fuzzy.csv is empty (STEP 5 matched 0 pairs).\")\n",
    "if df_elem.empty:\n",
    "    raise ValueError(\"element_similarity_exact_titles.csv is empty (STEP 6 matched 0 pairs).\")\n",
    "\n",
    "# ============================================================\n",
    "# 1) FULL-DOCUMENT LEVEL SUMMARY (Mean by Generated_File)\n",
    "# ============================================================\n",
    "project_col = \"Generated_File\" if \"Generated_File\" in df_full.columns else df_full.columns[0]\n",
    "\n",
    "sbert_col = next((c for c in df_full.columns if \"sbert\" in c.lower()), None)\n",
    "rouge_col = next((c for c in df_full.columns if \"rouge\" in c.lower()), None)\n",
    "\n",
    "if not sbert_col or not rouge_col:\n",
    "    raise ValueError(f\"Could not find SBERT/ROUGE columns in: {df_full.columns.tolist()}\")\n",
    "\n",
    "df_full_summary = (\n",
    "    df_full.groupby(project_col)[[sbert_col, rouge_col]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# numeric + formatted columns\n",
    "df_full_summary[\"SBERT_mean\"] = df_full_summary[sbert_col].round(4)\n",
    "df_full_summary[\"ROUGE_mean\"] = df_full_summary[rouge_col].round(4)\n",
    "\n",
    "df_full_table = df_full_summary[[project_col, \"SBERT_mean\", \"ROUGE_mean\"]].rename(\n",
    "    columns={project_col: \"Generated_File\"}\n",
    ")\n",
    "\n",
    "print(\"\\nFull-document summary (mean by Generated_File):\")\n",
    "display(df_full_table)\n",
    "\n",
    "# Optional overall mean (across projects)\n",
    "overall_full = {\n",
    "    \"SBERT_overall_mean\": float(df_full_summary[\"SBERT_mean\"].mean()),\n",
    "    \"ROUGE_overall_mean\": float(df_full_summary[\"ROUGE_mean\"].mean()),\n",
    "}\n",
    "print(\"\\nOverall full-document means:\")\n",
    "print(overall_full)\n",
    "\n",
    "# ============================================================\n",
    "# 2) ELEMENT-LEVEL SUMMARY (Mean ± SD)\n",
    "# ============================================================\n",
    "elem_col = next((c for c in df_elem.columns if \"element\" in c.lower()), None)\n",
    "if not elem_col:\n",
    "    raise ValueError(f\"Could not find element column in: {df_elem.columns.tolist()}\")\n",
    "\n",
    "sbert_col_e = next((c for c in df_elem.columns if \"sbert\" in c.lower()), None)\n",
    "rouge_col_e = next((c for c in df_elem.columns if \"rouge\" in c.lower()), None)\n",
    "\n",
    "if not sbert_col_e or not rouge_col_e:\n",
    "    raise ValueError(f\"Could not find SBERT/ROUGE columns in: {df_elem.columns.tolist()}\")\n",
    "\n",
    "df_elem_summary = (\n",
    "    df_elem.groupby(elem_col)[[sbert_col_e, rouge_col_e]]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten columns\n",
    "df_elem_summary.columns = [\n",
    "    elem_col,\n",
    "    \"SBERT_mean\", \"SBERT_sd\",\n",
    "    \"ROUGE_mean\", \"ROUGE_sd\"\n",
    "]\n",
    "\n",
    "# Round for readability\n",
    "for c in [\"SBERT_mean\", \"SBERT_sd\", \"ROUGE_mean\", \"ROUGE_sd\"]:\n",
    "    df_elem_summary[c] = df_elem_summary[c].astype(float).round(4)\n",
    "\n",
    "# Add formatted strings (mean ± sd)\n",
    "df_elem_summary[\"SBERT_mean_sd\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['SBERT_mean']:.2f} ± {r['SBERT_sd']:.2f}\", axis=1\n",
    ")\n",
    "df_elem_summary[\"ROUGE_mean_sd\"] = df_elem_summary.apply(\n",
    "    lambda r: f\"{r['ROUGE_mean']:.2f} ± {r['ROUGE_sd']:.2f}\", axis=1\n",
    ")\n",
    "\n",
    "df_elem_table = df_elem_summary[[elem_col, \"SBERT_mean_sd\", \"ROUGE_mean_sd\"]].rename(\n",
    "    columns={elem_col: \"Element\"}\n",
    ")\n",
    "\n",
    "print(\"\\nElement-level summary (mean ± sd):\")\n",
    "display(df_elem_table)\n",
    "\n",
    "# ============================================================\n",
    "# Save tables\n",
    "# ============================================================\n",
    "out_full = EVAL_DIR / \"summary_full_table_mean_only.csv\"\n",
    "out_elem = EVAL_DIR / \"summary_element_table_mean_sd.csv\"\n",
    "\n",
    "df_full_table.to_csv(out_full, index=False, encoding=\"utf-8\")\n",
    "df_elem_table.to_csv(out_elem, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nSaved formatted tables:\")\n",
    "print(out_full)\n",
    "print(out_elem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
